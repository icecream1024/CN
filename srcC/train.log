[2023-08-08 15:55:11,780][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2023-08-08 15:55:11,786][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2023-08-08 15:55:11,877][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2023-08-08 15:55:11,890][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2023-08-08 15:55:11,906][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
TypeError: __init__() missing 1 required positional argument: 'num_classes'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 53, in train
    model: LightningModule = hydra.utils.instantiate(cfg.model)
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 342, in instantiate_node
    value = instantiate_node(
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'srcC.models.components.net.network':
TypeError("__init__() missing 1 required positional argument: 'num_classes'")
full_key: model.net
[2023-08-08 15:55:11,908][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2023-08-08_15-55-11
[2023-08-08 15:58:37,888][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2023-08-08 15:58:37,894][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2023-08-08 15:58:37,979][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2023-08-08 15:58:37,985][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2023-08-08 15:58:38,007][__main__][INFO] - Instantiating callbacks...
[2023-08-08 15:58:38,008][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2023-08-08 15:58:38,013][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2023-08-08 15:58:38,015][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2023-08-08 15:58:38,016][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2023-08-08 15:58:38,018][__main__][INFO] - Instantiating loggers...
[2023-08-08 15:58:38,019][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2023-08-08 15:59:00,699][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2023-08-08 15:59:01,612][__main__][INFO] - Logging hyperparameters!
[2023-08-08 15:59:01,615][__main__][INFO] - Starting training!
[2023-08-08 16:00:09,805][__main__][INFO] - Starting testing!
[2023-08-08 16:00:17,241][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2023-08-08_15-58-37\checkpoints\epoch_001.ckpt
[2023-08-08 16:00:17,243][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2023-08-08_15-58-37
[2023-08-08 16:00:17,243][src.utils.utils][INFO] - Closing wandb!
[2023-08-08 16:00:24,415][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 11:29:43,701][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 11:29:43,708][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 11:29:43,779][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 11:29:43,784][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 11:29:43,808][__main__][INFO] - Instantiating callbacks...
[2024-01-30 11:29:43,808][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 11:29:43,812][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 11:29:43,813][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 11:29:43,813][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 11:29:43,816][__main__][INFO] - Instantiating loggers...
[2024-01-30 11:29:43,816][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 11:30:13,229][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 11:30:13,819][__main__][INFO] - Logging hyperparameters!
[2024-01-30 11:30:13,822][__main__][INFO] - Starting training!
[2024-01-30 11:32:34,831][__main__][INFO] - Starting testing!
[2024-01-30 11:32:40,004][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_11-29-43\checkpoints\epoch_005.ckpt
[2024-01-30 11:32:40,005][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_11-29-43
[2024-01-30 11:32:40,005][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 11:32:50,557][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 11:33:03,914][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 11:33:03,921][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 11:33:03,991][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 11:33:03,995][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 11:33:04,011][__main__][INFO] - Instantiating callbacks...
[2024-01-30 11:33:04,011][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 11:33:04,014][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 11:33:04,015][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 11:33:04,016][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 11:33:04,017][__main__][INFO] - Instantiating loggers...
[2024-01-30 11:33:04,018][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 11:33:31,687][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 11:33:32,265][__main__][INFO] - Logging hyperparameters!
[2024-01-30 11:33:32,268][__main__][INFO] - Starting training!
[2024-01-30 11:35:14,674][__main__][INFO] - Starting testing!
[2024-01-30 11:35:19,645][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_11-33-03\checkpoints\epoch_001.ckpt
[2024-01-30 11:35:19,647][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_11-33-03
[2024-01-30 11:35:19,647][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 11:35:30,647][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 13:17:51,208][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:17:51,215][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:17:51,291][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:17:51,297][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:17:51,354][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:17:51,354][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:17:51,357][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:17:51,359][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:17:51,360][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:17:51,361][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:17:51,362][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:18:29,163][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:18:29,859][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:18:29,863][__main__][INFO] - Starting training!
[2024-01-30 13:18:38,118][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:18:38,124][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-17-51
[2024-01-30 13:18:38,125][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:20:40,237][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:20:40,248][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:20:40,368][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:20:40,374][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:20:40,399][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:20:40,400][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:20:40,409][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:20:40,412][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:20:40,413][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:20:40,415][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:20:40,416][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:21:09,612][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:21:10,239][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:21:10,242][__main__][INFO] - Starting training!
[2024-01-30 13:21:15,012][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:21:15,016][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-20-40
[2024-01-30 13:21:15,017][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:22:01,870][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:22:01,881][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:22:02,071][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:22:02,090][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:22:02,134][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:22:02,136][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:22:02,145][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:22:02,150][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:22:02,151][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:22:02,157][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:22:02,158][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:22:35,140][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:22:35,655][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:22:35,659][__main__][INFO] - Starting training!
[2024-01-30 13:22:40,348][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:22:40,351][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-22-01
[2024-01-30 13:22:40,352][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:24:01,170][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:24:01,180][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:24:01,285][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:24:01,290][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:24:01,313][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:24:01,313][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:24:01,321][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:24:01,323][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:24:01,324][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:24:01,325][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:24:01,327][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:24:30,795][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:24:31,393][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:24:31,397][__main__][INFO] - Starting training!
[2024-01-30 13:24:36,409][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:24:36,413][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-24-01
[2024-01-30 13:24:36,413][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:25:48,281][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:25:48,289][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:25:48,378][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:25:48,384][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:25:48,405][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:25:48,405][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:25:48,411][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:25:48,413][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:25:48,414][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:25:48,416][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:25:48,416][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:26:19,405][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:26:20,003][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:26:20,007][__main__][INFO] - Starting training!
[2024-01-30 13:26:24,641][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters(), lr_min=1e-5, lr_max=1e-2)
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:26:24,645][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-25-48
[2024-01-30 13:26:24,645][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:27:39,677][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:27:39,685][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:27:39,776][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:27:39,786][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:27:39,820][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:27:39,820][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:27:39,826][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:27:39,829][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:27:39,830][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:27:39,831][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:27:39,832][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:28:10,870][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:28:11,341][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:28:11,343][__main__][INFO] - Starting training!
[2024-01-30 13:28:16,873][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:28:16,877][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-27-39
[2024-01-30 13:28:16,878][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:30:20,386][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:30:20,393][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:30:20,496][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:30:20,501][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:30:20,520][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:30:20,521][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:30:20,526][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:30:20,529][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:30:20,530][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:30:20,531][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:30:20,531][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:30:50,794][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:30:51,259][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:30:51,261][__main__][INFO] - Starting training!
[2024-01-30 13:30:55,957][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters(), lr_min=1e-5, lr_max=1e-2)
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:30:55,960][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-30-20
[2024-01-30 13:30:55,961][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:31:35,819][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:31:35,827][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:31:35,917][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:31:35,922][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:31:35,941][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:31:35,941][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:31:35,946][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:31:35,946][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:31:35,947][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:31:35,949][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:31:35,949][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:32:04,309][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:32:05,012][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:32:05,014][__main__][INFO] - Starting training!
[2024-01-30 13:32:09,697][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 201, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:32:09,700][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-31-35
[2024-01-30 13:32:09,701][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:33:11,194][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:33:11,203][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:33:11,319][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:33:11,327][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:33:11,358][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:33:11,358][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:33:11,366][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:33:11,370][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:33:11,371][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:33:11,373][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:33:11,374][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:33:40,071][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:33:40,702][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:33:40,705][__main__][INFO] - Starting training!
[2024-01-30 13:33:45,441][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 201, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:33:45,444][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-33-11
[2024-01-30 13:33:45,445][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:34:36,082][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:34:36,089][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:34:36,184][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:34:36,189][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:34:36,208][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:34:36,209][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:34:36,213][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:34:36,216][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:34:36,217][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:34:36,218][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:34:36,218][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:35:10,662][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:35:11,426][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:35:11,429][__main__][INFO] - Starting training!
[2024-01-30 13:35:16,623][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 201, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:35:16,627][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-34-35
[2024-01-30 13:35:16,627][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:36:34,676][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:36:34,683][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:36:34,759][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:36:34,764][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:36:34,785][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:36:34,785][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:36:34,789][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:36:34,790][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:36:34,791][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:36:34,791][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:36:34,793][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:37:02,707][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:37:03,350][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:37:03,353][__main__][INFO] - Starting training!
[2024-01-30 13:37:32,459][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 202, in run
    self.on_advance_end()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 377, in on_advance_end
    self.epoch_loop.update_lr_schedulers("epoch", update_plateau_schedulers=not self.restarting)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 300, in update_lr_schedulers
    self._update_learning_rates(interval=interval, update_plateau_schedulers=update_plateau_schedulers)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 350, in _update_learning_rates
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1216, in lr_scheduler_step
    scheduler.step(metric)
  File "D:\Anaconda3\lib\site-packages\torch\optim\lr_scheduler.py", line 1031, in step
    self._last_lr = [group['lr'] for group in self.optimizer.param_groups]
  File "D:\Anaconda3\lib\site-packages\torch\optim\lr_scheduler.py", line 1031, in <listcomp>
    self._last_lr = [group['lr'] for group in self.optimizer.param_groups]
KeyError: 'lr'
[2024-01-30 13:37:32,465][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-36-34
[2024-01-30 13:37:32,465][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:38:48,326][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:38:48,336][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:38:48,448][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:38:48,453][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:38:48,474][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:38:48,474][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:38:48,478][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:38:48,480][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:38:48,481][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:38:48,481][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:38:48,483][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:39:23,385][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:39:24,013][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:39:24,016][__main__][INFO] - Starting training!
[2024-01-30 13:39:48,860][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 202, in run
    self.on_advance_end()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 377, in on_advance_end
    self.epoch_loop.update_lr_schedulers("epoch", update_plateau_schedulers=not self.restarting)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 300, in update_lr_schedulers
    self._update_learning_rates(interval=interval, update_plateau_schedulers=update_plateau_schedulers)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 350, in _update_learning_rates
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1216, in lr_scheduler_step
    scheduler.step(metric)
  File "D:\Anaconda3\lib\site-packages\torch\optim\lr_scheduler.py", line 1031, in step
    self._last_lr = [group['lr'] for group in self.optimizer.param_groups]
  File "D:\Anaconda3\lib\site-packages\torch\optim\lr_scheduler.py", line 1031, in <listcomp>
    self._last_lr = [group['lr'] for group in self.optimizer.param_groups]
KeyError: 'lr'
[2024-01-30 13:39:48,864][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-38-48
[2024-01-30 13:39:48,865][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:41:16,878][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:41:16,888][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:41:16,986][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:41:16,991][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:41:17,010][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:41:17,010][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:41:17,016][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:41:17,017][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:41:17,018][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:41:17,019][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:41:17,019][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:41:45,734][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:41:46,354][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:41:46,357][__main__][INFO] - Starting training!
[2024-01-30 13:41:50,959][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 201, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters(), lr=1e-5)  # 
TypeError: __init__() got an unexpected keyword argument 'lr'
[2024-01-30 13:41:50,965][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-41-16
[2024-01-30 13:41:50,965][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:44:01,687][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:44:01,695][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:44:01,772][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:44:01,777][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:44:01,799][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:44:01,800][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:44:01,803][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:44:01,805][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:44:01,806][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:44:01,808][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:44:01,808][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:44:33,577][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:44:34,005][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:44:34,009][__main__][INFO] - Starting training!
[2024-01-30 13:46:47,565][__main__][INFO] - Starting testing!
[2024-01-30 13:46:53,101][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-44-01\checkpoints\epoch_004.ckpt
[2024-01-30 13:46:53,103][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-44-01
[2024-01-30 13:46:53,105][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:47:03,275][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 13:54:17,859][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:54:17,867][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:54:17,945][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:54:17,950][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:54:17,969][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:54:17,969][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:54:17,974][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:54:17,975][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:54:17,976][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:54:17,977][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:54:17,977][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:54:48,728][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:54:49,672][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:54:49,677][__main__][INFO] - Starting training!
[2024-01-30 13:54:57,336][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\Optimizer.py", line 51, in step
    angle = torch.dot(grad, prev_grad) / (torch.norm(grad) * torch.norm(prev_grad) + group['eps'])
RuntimeError: 1D tensors expected, but got 4D and 4D tensors
[2024-01-30 13:54:57,345][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-54-17
[2024-01-30 13:54:57,346][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:55:50,951][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:55:50,958][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:55:51,052][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:55:51,057][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:55:51,077][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:55:51,077][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:55:51,082][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:55:51,083][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:55:51,083][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:55:51,084][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:55:51,084][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:56:20,114][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:56:20,782][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:56:20,784][__main__][INFO] - Starting training!
[2024-01-30 13:56:28,029][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\Optimizer.py", line 80, in step
    p.data.addcdiv_(-step_size, momentum_term, denom)
RuntimeError: The size of tensor a (3) must match the size of tensor b (432) at non-singleton dimension 3
[2024-01-30 13:56:28,034][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-55-50
[2024-01-30 13:56:28,034][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:57:19,583][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:57:19,591][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:57:19,712][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:57:19,720][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:57:19,740][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:57:19,741][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:57:19,745][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:57:19,745][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:57:19,746][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:57:19,747][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:57:19,747][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:57:52,528][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:57:53,839][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:57:53,843][__main__][INFO] - Starting training!
[2024-01-30 13:58:02,241][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\Optimizer.py", line 80, in step
    p.data.addcdiv_(-step_size, momentum_term, denom)
RuntimeError: The size of tensor a (3) must match the size of tensor b (432) at non-singleton dimension 3
[2024-01-30 13:58:02,246][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-57-19
[2024-01-30 13:58:02,246][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 13:58:57,031][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 13:58:57,040][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 13:58:57,127][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 13:58:57,132][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 13:58:57,158][__main__][INFO] - Instantiating callbacks...
[2024-01-30 13:58:57,159][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 13:58:57,165][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 13:58:57,168][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 13:58:57,169][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 13:58:57,170][__main__][INFO] - Instantiating loggers...
[2024-01-30 13:58:57,171][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 13:59:30,298][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 13:59:30,820][__main__][INFO] - Logging hyperparameters!
[2024-01-30 13:59:30,823][__main__][INFO] - Starting training!
[2024-01-30 13:59:38,750][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\Optimizer.py", line 80, in step
    p.data.addcdiv_(-step_size, momentum_term, denom)
RuntimeError: The size of tensor a (3) must match the size of tensor b (432) at non-singleton dimension 3
[2024-01-30 13:59:38,755][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_13-58-56
[2024-01-30 13:59:38,755][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 14:00:42,895][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 14:00:42,902][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 14:00:42,979][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 14:00:42,983][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 14:00:43,004][__main__][INFO] - Instantiating callbacks...
[2024-01-30 14:00:43,005][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 14:00:43,009][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 14:00:43,011][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 14:00:43,012][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 14:00:43,013][__main__][INFO] - Instantiating loggers...
[2024-01-30 14:00:43,014][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 14:01:18,370][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 14:01:19,881][__main__][INFO] - Logging hyperparameters!
[2024-01-30 14:01:19,884][__main__][INFO] - Starting training!
[2024-01-30 14:02:48,838][__main__][INFO] - Starting testing!
[2024-01-30 14:07:48,999][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 14:07:49,008][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 14:07:49,103][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 14:07:49,110][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 14:07:49,133][__main__][INFO] - Instantiating callbacks...
[2024-01-30 14:07:49,134][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 14:07:49,138][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 14:07:49,140][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 14:07:49,141][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 14:07:49,142][__main__][INFO] - Instantiating loggers...
[2024-01-30 14:07:49,143][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 14:08:23,182][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 14:08:23,797][__main__][INFO] - Logging hyperparameters!
[2024-01-30 14:08:23,801][__main__][INFO] - Starting training!
[2024-01-30 14:10:51,369][__main__][INFO] - Starting testing!
[2024-01-30 14:10:57,335][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-07-48\checkpoints\epoch_004.ckpt
[2024-01-30 14:10:57,336][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-07-48
[2024-01-30 14:10:57,337][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 14:11:08,242][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 14:13:28,666][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 14:13:28,674][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 14:13:28,757][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 14:13:28,762][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 14:13:28,784][__main__][INFO] - Instantiating callbacks...
[2024-01-30 14:13:28,785][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 14:13:28,790][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 14:13:28,792][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 14:13:28,793][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 14:13:28,794][__main__][INFO] - Instantiating loggers...
[2024-01-30 14:13:28,795][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 14:14:05,065][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 14:14:05,934][__main__][INFO] - Logging hyperparameters!
[2024-01-30 14:14:05,939][__main__][INFO] - Starting training!
[2024-01-30 14:17:13,689][__main__][INFO] - Starting testing!
[2024-01-30 14:17:19,464][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-13-28\checkpoints\epoch_004.ckpt
[2024-01-30 14:17:19,465][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-13-28
[2024-01-30 14:17:19,466][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 14:17:31,082][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 14:19:16,619][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 14:19:16,630][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 14:19:16,730][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 14:19:16,734][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 14:19:16,759][__main__][INFO] - Instantiating callbacks...
[2024-01-30 14:19:16,759][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 14:19:16,764][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 14:19:16,765][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 14:19:16,767][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 14:19:16,769][__main__][INFO] - Instantiating loggers...
[2024-01-30 14:19:16,769][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 14:19:46,649][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 14:19:47,249][__main__][INFO] - Logging hyperparameters!
[2024-01-30 14:19:47,252][__main__][INFO] - Starting training!
[2024-01-30 14:22:12,200][__main__][INFO] - Starting testing!
[2024-01-30 14:22:18,815][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-19-16\checkpoints\epoch_003.ckpt
[2024-01-30 14:22:18,816][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-19-16
[2024-01-30 14:22:18,818][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 14:22:30,773][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 14:22:43,875][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 14:22:43,883][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 14:22:43,968][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 14:22:43,973][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 14:22:43,990][__main__][INFO] - Instantiating callbacks...
[2024-01-30 14:22:43,990][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 14:22:43,994][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 14:22:43,996][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 14:22:43,997][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 14:22:44,000][__main__][INFO] - Instantiating loggers...
[2024-01-30 14:22:44,000][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 14:23:17,188][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 14:23:17,930][__main__][INFO] - Logging hyperparameters!
[2024-01-30 14:23:17,936][__main__][INFO] - Starting training!
[2024-01-30 14:25:43,000][__main__][INFO] - Starting testing!
[2024-01-30 14:25:48,348][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-22-43\checkpoints\epoch_005.ckpt
[2024-01-30 14:25:48,350][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-22-43
[2024-01-30 14:25:48,350][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 14:25:59,452][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 14:28:07,871][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 14:28:07,878][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 14:28:07,966][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 14:28:07,971][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 14:28:07,989][__main__][INFO] - Instantiating callbacks...
[2024-01-30 14:28:07,990][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 14:28:07,994][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 14:28:07,996][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 14:28:07,996][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 14:28:07,998][__main__][INFO] - Instantiating loggers...
[2024-01-30 14:28:07,998][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 14:28:37,224][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 14:28:37,864][__main__][INFO] - Logging hyperparameters!
[2024-01-30 14:28:37,868][__main__][INFO] - Starting training!
[2024-01-30 14:32:28,788][__main__][INFO] - Starting testing!
[2024-01-30 14:32:33,788][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-28-07\checkpoints\epoch_009.ckpt
[2024-01-30 14:32:33,791][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-28-07
[2024-01-30 14:32:33,791][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 14:32:46,434][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 14:39:24,035][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 14:39:24,047][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 14:39:24,212][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 14:39:24,229][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 14:39:24,285][__main__][INFO] - Instantiating callbacks...
[2024-01-30 14:39:24,286][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 14:39:24,294][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 14:39:24,301][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 14:39:24,302][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 14:39:24,305][__main__][INFO] - Instantiating loggers...
[2024-01-30 14:39:24,305][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 14:39:55,206][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 14:39:55,825][__main__][INFO] - Logging hyperparameters!
[2024-01-30 14:39:55,830][__main__][INFO] - Starting training!
[2024-01-30 14:43:44,542][__main__][INFO] - Starting testing!
[2024-01-30 14:43:50,280][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-39-23\checkpoints\epoch_009.ckpt
[2024-01-30 14:43:50,281][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_14-39-23
[2024-01-30 14:43:50,282][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 14:44:01,127][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 15:18:06,971][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 15:18:06,977][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 15:18:07,056][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 15:18:07,061][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 15:18:07,079][__main__][INFO] - Instantiating callbacks...
[2024-01-30 15:18:07,080][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 15:18:07,084][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 15:18:07,087][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 15:18:07,088][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 15:18:07,089][__main__][INFO] - Instantiating loggers...
[2024-01-30 15:18:07,090][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 15:18:36,227][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 15:18:36,892][__main__][INFO] - Logging hyperparameters!
[2024-01-30 15:18:36,895][__main__][INFO] - Starting training!
[2024-01-30 15:22:54,418][__main__][INFO] - Starting testing!
[2024-01-30 15:23:02,888][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-18-06\checkpoints\epoch_006.ckpt
[2024-01-30 15:23:02,890][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-18-06
[2024-01-30 15:23:02,890][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 15:23:13,287][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 15:25:31,888][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 15:25:31,895][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 15:25:31,983][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 15:25:31,987][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 15:25:32,008][__main__][INFO] - Instantiating callbacks...
[2024-01-30 15:25:32,009][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 15:25:32,014][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 15:25:32,015][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 15:25:32,017][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 15:25:32,018][__main__][INFO] - Instantiating loggers...
[2024-01-30 15:25:32,018][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 15:26:11,956][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 15:26:12,896][__main__][INFO] - Logging hyperparameters!
[2024-01-30 15:26:12,900][__main__][INFO] - Starting training!
[2024-01-30 15:30:44,029][__main__][INFO] - Starting testing!
[2024-01-30 15:30:49,768][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-25-31\checkpoints\epoch_008.ckpt
[2024-01-30 15:30:49,770][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-25-31
[2024-01-30 15:30:49,770][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 15:31:01,140][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 15:34:04,992][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 15:34:05,000][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 15:34:05,085][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 15:34:05,089][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 15:34:05,106][__main__][INFO] - Instantiating callbacks...
[2024-01-30 15:34:05,107][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 15:34:05,112][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 15:34:05,114][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 15:34:05,114][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 15:34:05,116][__main__][INFO] - Instantiating loggers...
[2024-01-30 15:34:05,116][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 15:34:16,223][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-34-04
[2024-01-30 15:35:22,396][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 15:35:22,404][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 15:35:22,488][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 15:35:22,492][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 15:35:22,511][__main__][INFO] - Instantiating callbacks...
[2024-01-30 15:35:22,511][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 15:35:22,515][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 15:35:22,516][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 15:35:22,516][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 15:35:22,518][__main__][INFO] - Instantiating loggers...
[2024-01-30 15:35:22,518][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 15:35:50,009][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 15:35:50,473][__main__][INFO] - Logging hyperparameters!
[2024-01-30 15:35:50,476][__main__][INFO] - Starting training!
[2024-01-30 15:41:01,416][__main__][INFO] - Starting testing!
[2024-01-30 15:41:08,490][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-35-22\checkpoints\epoch_006.ckpt
[2024-01-30 15:41:08,492][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-35-22
[2024-01-30 15:41:08,492][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 15:41:19,166][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 15:56:49,404][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 15:56:49,411][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 15:56:49,507][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 15:56:49,512][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 15:56:49,534][__main__][INFO] - Instantiating callbacks...
[2024-01-30 15:56:49,534][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 15:56:49,541][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 15:56:49,542][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 15:56:49,542][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 15:56:49,544][__main__][INFO] - Instantiating loggers...
[2024-01-30 15:56:49,544][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 15:57:19,102][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 15:57:19,715][__main__][INFO] - Logging hyperparameters!
[2024-01-30 15:57:19,718][__main__][INFO] - Starting training!
[2024-01-30 16:02:54,069][__main__][INFO] - Starting testing!
[2024-01-30 16:02:59,744][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-56-49\checkpoints\epoch_007.ckpt
[2024-01-30 16:02:59,746][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_15-56-49
[2024-01-30 16:02:59,746][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 16:03:12,659][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 16:04:07,304][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 16:04:07,313][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 16:04:07,430][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 16:04:07,437][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 16:04:07,464][__main__][INFO] - Instantiating callbacks...
[2024-01-30 16:04:07,465][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 16:04:07,472][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 16:04:07,475][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 16:04:07,476][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 16:04:07,479][__main__][INFO] - Instantiating loggers...
[2024-01-30 16:04:07,480][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 16:04:40,543][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 16:04:41,306][__main__][INFO] - Logging hyperparameters!
[2024-01-30 16:04:41,310][__main__][INFO] - Starting training!
[2024-01-30 16:10:36,277][__main__][INFO] - Starting testing!
[2024-01-30 16:10:43,676][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_16-04-07\checkpoints\epoch_010.ckpt
[2024-01-30 16:10:43,679][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_16-04-07
[2024-01-30 16:10:43,679][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 16:10:55,934][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 16:15:32,385][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 16:15:32,394][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 16:15:32,509][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 16:15:32,515][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 16:15:32,540][__main__][INFO] - Instantiating callbacks...
[2024-01-30 16:15:32,541][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 16:15:32,548][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 16:15:32,550][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 16:15:32,551][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 16:15:32,553][__main__][INFO] - Instantiating loggers...
[2024-01-30 16:15:32,553][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 16:16:08,970][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 16:16:09,637][__main__][INFO] - Logging hyperparameters!
[2024-01-30 16:16:09,640][__main__][INFO] - Starting training!
[2024-01-30 16:21:50,385][__main__][INFO] - Starting testing!
[2024-01-30 16:21:57,772][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_16-15-32\checkpoints\epoch_007.ckpt
[2024-01-30 16:21:57,774][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_16-15-32
[2024-01-30 16:21:57,775][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 16:22:10,330][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 16:22:55,015][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 16:22:55,023][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 16:22:55,125][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 16:22:55,129][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 16:22:55,148][__main__][INFO] - Instantiating callbacks...
[2024-01-30 16:22:55,148][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 16:22:55,152][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 16:22:55,153][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 16:22:55,155][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 16:22:55,156][__main__][INFO] - Instantiating loggers...
[2024-01-30 16:22:55,156][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 16:23:31,712][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 16:23:32,770][__main__][INFO] - Logging hyperparameters!
[2024-01-30 16:23:32,777][__main__][INFO] - Starting training!
[2024-01-30 16:30:11,336][__main__][INFO] - Starting testing!
[2024-01-30 16:30:17,074][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_16-22-54\checkpoints\epoch_007.ckpt
[2024-01-30 16:30:17,076][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_16-22-54
[2024-01-30 16:30:17,077][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 16:30:27,779][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 16:32:07,908][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 16:32:07,915][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 16:32:08,014][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 16:32:08,019][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 16:32:08,039][__main__][INFO] - Instantiating callbacks...
[2024-01-30 16:32:08,040][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 16:32:08,044][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 16:32:08,046][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 16:32:08,047][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 16:32:08,048][__main__][INFO] - Instantiating loggers...
[2024-01-30 16:32:08,048][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 16:32:40,460][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 16:32:41,205][__main__][INFO] - Logging hyperparameters!
[2024-01-30 16:32:41,208][__main__][INFO] - Starting training!
[2024-01-30 16:39:06,456][__main__][INFO] - Starting testing!
[2024-01-30 16:39:22,846][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 16:39:22,853][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 16:39:22,945][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 16:39:22,950][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 16:39:22,969][__main__][INFO] - Instantiating callbacks...
[2024-01-30 16:39:22,969][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 16:39:22,975][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 16:39:22,977][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 16:39:22,978][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 16:39:22,979][__main__][INFO] - Instantiating loggers...
[2024-01-30 16:39:22,979][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 16:39:56,738][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 16:39:57,371][__main__][INFO] - Logging hyperparameters!
[2024-01-30 16:39:57,375][__main__][INFO] - Starting training!
[2024-01-30 16:41:52,428][__main__][INFO] - Starting testing!
[2024-01-30 16:41:58,697][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_16-39-22\checkpoints\epoch_000.ckpt
[2024-01-30 16:41:58,699][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_16-39-22
[2024-01-30 16:41:58,699][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 16:42:13,066][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 17:00:28,600][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 17:00:28,610][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 17:00:28,720][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 17:00:28,726][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 17:00:28,808][__main__][INFO] - Instantiating callbacks...
[2024-01-30 17:00:28,809][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 17:00:28,818][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 17:00:28,822][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 17:00:28,823][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 17:00:28,826][__main__][INFO] - Instantiating loggers...
[2024-01-30 17:00:28,831][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 17:01:06,206][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 17:01:06,819][__main__][INFO] - Logging hyperparameters!
[2024-01-30 17:01:06,822][__main__][INFO] - Starting training!
[2024-01-30 17:06:19,392][__main__][INFO] - Starting testing!
[2024-01-30 17:06:25,693][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_17-00-28\checkpoints\epoch_007.ckpt
[2024-01-30 17:06:25,695][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_17-00-28
[2024-01-30 17:06:25,695][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 17:06:46,348][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 17:06:46,394][urllib3.connectionpool][WARNING] - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000016EFA932580>: Failed to establish a new connection: [WinError 10061] '))': /api/4504800232407040/envelope/
[2024-01-30 17:55:48,653][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 17:55:48,663][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 17:55:48,784][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 17:55:48,793][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 17:55:48,831][__main__][INFO] - Instantiating callbacks...
[2024-01-30 17:55:48,832][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 17:55:48,842][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 17:55:48,845][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 17:55:48,845][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 17:55:48,847][__main__][INFO] - Instantiating loggers...
[2024-01-30 17:55:48,848][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 17:56:20,912][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 17:56:21,575][__main__][INFO] - Logging hyperparameters!
[2024-01-30 17:56:21,579][__main__][INFO] - Starting training!
[2024-01-30 18:00:34,410][__main__][INFO] - Starting testing!
[2024-01-30 18:00:40,747][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_17-55-48\checkpoints\epoch_007.ckpt
[2024-01-30 18:00:40,749][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_17-55-48
[2024-01-30 18:00:40,750][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 18:00:50,398][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 18:12:19,787][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 18:12:19,794][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 18:12:19,870][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 18:12:19,875][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 18:12:19,897][__main__][INFO] - Instantiating callbacks...
[2024-01-30 18:12:19,900][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 18:12:19,905][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 18:12:19,907][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 18:12:19,907][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 18:12:19,909][__main__][INFO] - Instantiating loggers...
[2024-01-30 18:12:19,909][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 18:12:27,590][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_18-12-19
[2024-01-30 18:12:50,786][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 18:12:50,799][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 18:12:50,900][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 18:12:50,907][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 18:12:50,932][__main__][INFO] - Instantiating callbacks...
[2024-01-30 18:12:50,932][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 18:12:50,939][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 18:12:50,940][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 18:12:50,942][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 18:12:50,944][__main__][INFO] - Instantiating loggers...
[2024-01-30 18:12:50,944][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 18:13:37,494][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 18:13:38,132][__main__][INFO] - Logging hyperparameters!
[2024-01-30 18:13:38,135][__main__][INFO] - Starting training!
[2024-01-30 18:20:13,288][__main__][INFO] - Starting testing!
[2024-01-30 18:20:18,724][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_18-12-50\checkpoints\epoch_007.ckpt
[2024-01-30 18:20:18,726][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_18-12-50
[2024-01-30 18:20:18,726][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 18:20:29,056][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 18:30:18,055][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 18:30:18,062][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 18:30:18,147][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 18:30:18,151][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 18:30:18,179][__main__][INFO] - Instantiating callbacks...
[2024-01-30 18:30:18,180][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 18:30:18,183][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 18:30:18,184][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 18:30:18,185][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 18:30:18,186][__main__][INFO] - Instantiating loggers...
[2024-01-30 18:30:18,186][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 18:30:47,085][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 18:30:47,712][__main__][INFO] - Logging hyperparameters!
[2024-01-30 18:30:47,715][__main__][INFO] - Starting training!
[2024-01-30 18:30:53,492][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 379, in validation_step
    return self.model.validation_step(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 143, in validation_step
    loss, preds, targets = self.model_step(batch)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 107, in model_step
    logits = self.forward(x)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 84, in forward
    return self.net(x)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\components\net.py", line 96, in forward
    return self.model(x)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\container.py", line 217, in forward
    input = module(input)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x3072 and 784x256)
[2024-01-30 18:30:53,500][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_18-30-17
[2024-01-30 18:30:53,502][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 18:34:08,715][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 18:34:08,722][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 18:34:08,807][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 18:34:08,812][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 18:34:08,833][__main__][INFO] - Instantiating callbacks...
[2024-01-30 18:34:08,833][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 18:34:08,837][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 18:34:08,839][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 18:34:08,840][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 18:34:08,841][__main__][INFO] - Instantiating loggers...
[2024-01-30 18:34:08,841][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 18:34:37,771][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 18:34:38,383][__main__][INFO] - Logging hyperparameters!
[2024-01-30 18:34:38,386][__main__][INFO] - Starting training!
[2024-01-30 18:41:40,642][__main__][INFO] - Starting testing!
[2024-01-30 18:41:48,435][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_18-34-08\checkpoints\epoch_007.ckpt
[2024-01-30 18:41:48,438][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_18-34-08
[2024-01-30 18:41:48,438][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 18:41:59,837][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 18:47:45,637][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 18:47:45,646][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 18:47:45,749][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 18:47:45,754][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 18:47:45,772][__main__][INFO] - Instantiating callbacks...
[2024-01-30 18:47:45,773][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 18:47:45,778][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 18:47:45,780][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 18:47:45,780][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 18:47:45,782][__main__][INFO] - Instantiating loggers...
[2024-01-30 18:47:45,782][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 18:48:14,583][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 18:48:15,058][__main__][INFO] - Logging hyperparameters!
[2024-01-30 18:48:15,061][__main__][INFO] - Starting training!
[2024-01-30 18:54:38,844][__main__][INFO] - Starting testing!
[2024-01-30 18:54:44,620][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_18-47-45\checkpoints\epoch_008.ckpt
[2024-01-30 18:54:44,622][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-30_18-47-45
[2024-01-30 18:54:44,622][src.utils.utils][INFO] - Closing wandb!
[2024-01-30 18:54:56,282][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-30 19:22:23,708][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-30 19:22:23,715][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-30 19:22:23,807][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-30 19:22:23,815][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-30 19:22:23,838][__main__][INFO] - Instantiating callbacks...
[2024-01-30 19:22:23,839][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-30 19:22:23,843][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-30 19:22:23,845][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-30 19:22:23,846][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-30 19:22:23,847][__main__][INFO] - Instantiating loggers...
[2024-01-30 19:22:23,847][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-30 19:23:05,212][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-30 19:23:05,957][__main__][INFO] - Logging hyperparameters!
[2024-01-30 19:23:05,962][__main__][INFO] - Starting training!
[2024-01-30 19:25:22,012][__main__][INFO] - Starting testing!
[2024-01-31 09:58:07,227][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 09:58:07,235][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 09:58:07,313][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 09:58:07,319][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 09:58:07,366][__main__][INFO] - Instantiating callbacks...
[2024-01-31 09:58:07,366][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 09:58:07,371][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 09:58:07,372][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 09:58:07,373][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 09:58:07,374][__main__][INFO] - Instantiating loggers...
[2024-01-31 09:58:07,375][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 09:58:34,108][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 09:58:34,644][__main__][INFO] - Logging hyperparameters!
[2024-01-31 09:58:34,647][__main__][INFO] - Starting training!
[2024-01-31 10:03:33,912][__main__][INFO] - Starting testing!
[2024-01-31 10:03:39,322][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_09-58-07\checkpoints\epoch_012.ckpt
[2024-01-31 10:03:39,323][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_09-58-07
[2024-01-31 10:03:39,324][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 10:04:00,624][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-31 10:04:20,308][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 10:04:20,316][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 10:04:20,402][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 10:04:20,407][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 10:04:20,428][__main__][INFO] - Instantiating callbacks...
[2024-01-31 10:04:20,428][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 10:04:20,434][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 10:04:20,436][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 10:04:20,437][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 10:04:20,438][__main__][INFO] - Instantiating loggers...
[2024-01-31 10:04:20,439][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 10:04:58,263][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 10:04:58,899][__main__][INFO] - Logging hyperparameters!
[2024-01-31 10:04:58,903][__main__][INFO] - Starting training!
[2024-01-31 10:11:14,672][__main__][INFO] - Starting testing!
[2024-01-31 10:11:19,809][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-04-20\checkpoints\epoch_014.ckpt
[2024-01-31 10:11:19,811][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-04-20
[2024-01-31 10:11:19,812][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 10:11:44,934][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-31 10:13:26,494][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 10:13:26,501][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 10:13:26,633][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 10:13:26,641][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 10:13:26,672][__main__][INFO] - Instantiating callbacks...
[2024-01-31 10:13:26,672][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 10:13:26,679][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 10:13:26,682][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 10:13:26,684][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 10:13:26,686][__main__][INFO] - Instantiating loggers...
[2024-01-31 10:13:26,686][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 10:13:57,731][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 10:13:58,426][__main__][INFO] - Logging hyperparameters!
[2024-01-31 10:13:58,431][__main__][INFO] - Starting training!
[2024-01-31 10:15:50,215][__main__][INFO] - Starting testing!
[2024-01-31 10:15:56,346][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-13-26\checkpoints\epoch_003.ckpt
[2024-01-31 10:15:56,348][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-13-26
[2024-01-31 10:15:56,348][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 10:16:34,229][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 10:16:34,236][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 10:16:34,314][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 10:16:34,319][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 10:16:34,337][__main__][INFO] - Instantiating callbacks...
[2024-01-31 10:16:34,337][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 10:16:34,342][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 10:16:34,343][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 10:16:34,344][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 10:16:34,346][__main__][INFO] - Instantiating loggers...
[2024-01-31 10:16:34,346][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 10:17:04,306][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 10:17:04,850][__main__][INFO] - Logging hyperparameters!
[2024-01-31 10:17:04,854][__main__][INFO] - Starting training!
[2024-01-31 10:24:17,709][__main__][INFO] - Starting testing!
[2024-01-31 10:24:23,656][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-16-34\checkpoints\epoch_010.ckpt
[2024-01-31 10:24:23,657][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-16-34
[2024-01-31 10:24:23,658][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 10:24:48,584][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-01-31 10:53:11,654][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 10:53:11,661][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 10:53:11,769][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 10:53:11,774][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 10:53:11,793][__main__][INFO] - Instantiating callbacks...
[2024-01-31 10:53:11,793][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 10:53:11,798][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 10:53:11,800][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 10:53:11,800][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 10:53:11,801][__main__][INFO] - Instantiating loggers...
[2024-01-31 10:53:11,802][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 10:53:46,453][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 10:53:47,082][__main__][INFO] - Logging hyperparameters!
[2024-01-31 10:53:47,086][__main__][INFO] - Starting training!
[2024-01-31 10:53:51,642][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'weight_decay'
[2024-01-31 10:53:51,648][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-53-11
[2024-01-31 10:53:51,649][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 10:54:45,147][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 10:54:45,156][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 10:54:45,250][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 10:54:45,255][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 10:54:45,274][__main__][INFO] - Instantiating callbacks...
[2024-01-31 10:54:45,276][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 10:54:45,281][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 10:54:45,284][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 10:54:45,285][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 10:54:45,287][__main__][INFO] - Instantiating loggers...
[2024-01-31 10:54:45,288][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 10:55:15,735][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 10:55:16,228][__main__][INFO] - Logging hyperparameters!
[2024-01-31 10:55:16,231][__main__][INFO] - Starting training!
[2024-01-31 10:55:20,811][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 188, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'params'
[2024-01-31 10:55:20,815][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-54-44
[2024-01-31 10:55:20,816][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 10:56:43,851][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 10:56:43,860][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 10:56:43,942][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 10:56:43,947][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 10:56:43,964][__main__][INFO] - Instantiating callbacks...
[2024-01-31 10:56:43,965][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 10:56:43,970][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 10:56:43,971][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 10:56:43,972][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 10:56:43,973][__main__][INFO] - Instantiating loggers...
[2024-01-31 10:56:43,973][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 10:57:18,110][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 10:57:18,797][__main__][INFO] - Logging hyperparameters!
[2024-01-31 10:57:18,805][__main__][INFO] - Starting training!
[2024-01-31 10:57:23,945][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 190, in configure_optimizers
    scheduler = self.hparams.scheduler(optimizer=optimizer)
  File "D:\Anaconda3\lib\site-packages\torch\optim\lr_scheduler.py", line 973, in __init__
    raise TypeError('{} is not an Optimizer'.format(
TypeError: NesterovOptimizer is not an Optimizer
[2024-01-31 10:57:23,950][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-56-43
[2024-01-31 10:57:23,950][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 10:58:25,692][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 10:58:25,702][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 10:58:25,790][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 10:58:25,795][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 10:58:25,815][__main__][INFO] - Instantiating callbacks...
[2024-01-31 10:58:25,815][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 10:58:25,819][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 10:58:25,821][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 10:58:25,822][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 10:58:25,823][__main__][INFO] - Instantiating loggers...
[2024-01-31 10:58:25,823][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 10:58:55,462][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 10:58:56,105][__main__][INFO] - Logging hyperparameters!
[2024-01-31 10:58:56,108][__main__][INFO] - Starting training!
[2024-01-31 10:59:03,178][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 98, in step
    p.add_(buf, alpha=-group['lr'])
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
[2024-01-31 10:59:03,185][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_10-58-25
[2024-01-31 10:59:03,185][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 11:00:04,350][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 11:00:04,366][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 11:00:04,500][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 11:00:04,507][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 11:00:04,631][__main__][INFO] - Instantiating callbacks...
[2024-01-31 11:00:04,632][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 11:00:04,641][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 11:00:04,646][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 11:00:04,665][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 11:00:04,667][__main__][INFO] - Instantiating loggers...
[2024-01-31 11:00:04,668][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 11:00:42,236][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 11:00:42,890][__main__][INFO] - Logging hyperparameters!
[2024-01-31 11:00:42,893][__main__][INFO] - Starting training!
[2024-01-31 11:00:50,695][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 99, in step
    p.add_(momentum, alpha=-group['lr'])
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
[2024-01-31 11:00:50,699][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_11-00-04
[2024-01-31 11:00:50,700][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 11:01:52,597][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 11:01:52,605][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 11:01:52,686][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 11:01:52,691][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 11:01:52,709][__main__][INFO] - Instantiating callbacks...
[2024-01-31 11:01:52,710][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 11:01:52,714][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 11:01:52,715][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 11:01:52,715][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 11:01:52,717][__main__][INFO] - Instantiating loggers...
[2024-01-31 11:01:52,717][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 11:02:21,592][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 11:02:22,503][__main__][INFO] - Logging hyperparameters!
[2024-01-31 11:02:22,508][__main__][INFO] - Starting training!
[2024-01-31 11:02:29,672][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 99, in step
    p.add_(momentum, alpha=-group['lr'])
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
[2024-01-31 11:02:29,678][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_11-01-52
[2024-01-31 11:02:29,678][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 11:03:19,782][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 11:03:19,792][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 11:03:19,914][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 11:03:19,920][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 11:03:19,941][__main__][INFO] - Instantiating callbacks...
[2024-01-31 11:03:19,941][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 11:03:19,945][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 11:03:19,947][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 11:03:19,948][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 11:03:19,950][__main__][INFO] - Instantiating loggers...
[2024-01-31 11:03:19,951][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 11:04:00,842][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 11:04:01,545][__main__][INFO] - Logging hyperparameters!
[2024-01-31 11:04:01,549][__main__][INFO] - Starting training!
[2024-01-31 11:04:09,501][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 98, in step
    p.add_(momentum, alpha=-group['lr'])
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
[2024-01-31 11:04:09,507][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_11-03-19
[2024-01-31 11:04:09,508][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 11:05:43,375][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 11:05:43,388][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 11:05:43,486][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 11:05:43,492][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 11:05:43,515][__main__][INFO] - Instantiating callbacks...
[2024-01-31 11:05:43,516][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 11:05:43,521][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 11:05:43,523][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 11:05:43,524][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 11:05:43,525][__main__][INFO] - Instantiating loggers...
[2024-01-31 11:05:43,526][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 11:06:53,485][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loggers\wandb.py", line 358, in __init__
    _ = self.experiment
  File "D:\Anaconda3\lib\site-packages\lightning\fabric\loggers\logger.py", line 114, in experiment
    return fn(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loggers\wandb.py", line 406, in experiment
    self._experiment = wandb.init(**self._wandb_init)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_init.py", line 1166, in init
    raise e
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_init.py", line 1147, in init
    run = wi.init()
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_init.py", line 762, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 60.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 59, in train
    logger: List[Logger] = utils.instantiate_loggers(cfg.get("logger"))
  File "D:\pycharmproject\template\src\utils\instantiators.py", line 48, in instantiate_loggers
    logger.append(hydra.utils.instantiate(lg_conf))
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'lightning.pytorch.loggers.wandb.WandbLogger':
CommError('Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-')
full_key: logger.wandb
[2024-01-31 11:06:53,489][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_11-05-43
[2024-01-31 11:06:53,857][urllib3.connectionpool][WARNING] - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, '', None, 10054, None))': /api/4504800232407040/store/
[2024-01-31 11:06:56,246][urllib3.connectionpool][WARNING] - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, '', None, 10054, None))': /api/4504800232407040/store/
[2024-01-31 11:06:58,618][urllib3.connectionpool][WARNING] - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, '', None, 10054, None))': /api/4504800232407040/store/
[2024-01-31 11:07:47,509][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 11:07:47,519][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 11:07:47,604][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 11:07:47,611][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 11:07:47,637][__main__][INFO] - Instantiating callbacks...
[2024-01-31 11:07:47,638][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 11:07:47,642][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 11:07:47,643][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 11:07:47,644][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 11:07:47,648][__main__][INFO] - Instantiating loggers...
[2024-01-31 11:07:47,649][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 11:08:23,764][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 11:08:24,520][__main__][INFO] - Logging hyperparameters!
[2024-01-31 11:08:24,523][__main__][INFO] - Starting training!
[2024-01-31 11:08:33,135][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 99, in step
    p.add_(momentum, alpha=-group['lr'])
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
[2024-01-31 11:08:33,141][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_11-07-47
[2024-01-31 11:08:33,141][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 13:55:30,891][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 13:55:30,918][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 13:55:31,120][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 13:55:31,132][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 13:55:31,215][__main__][INFO] - Instantiating callbacks...
[2024-01-31 13:55:31,215][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 13:55:31,228][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 13:55:31,232][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 13:55:31,235][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 13:55:31,241][__main__][INFO] - Instantiating loggers...
[2024-01-31 13:55:31,242][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 13:56:09,270][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 13:56:10,140][__main__][INFO] - Logging hyperparameters!
[2024-01-31 13:56:10,145][__main__][INFO] - Starting training!
[2024-01-31 13:56:22,958][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 99, in step
    p.add_(momentum, alpha=-group['lr'])
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
[2024-01-31 13:56:22,967][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_13-55-30
[2024-01-31 13:56:22,967][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 13:59:41,950][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 13:59:41,958][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 13:59:42,068][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 13:59:42,075][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 13:59:42,113][__main__][INFO] - Instantiating callbacks...
[2024-01-31 13:59:42,114][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 13:59:42,124][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 13:59:42,128][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 13:59:42,129][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 13:59:42,132][__main__][INFO] - Instantiating loggers...
[2024-01-31 13:59:42,132][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 14:00:17,521][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 14:00:18,291][__main__][INFO] - Logging hyperparameters!
[2024-01-31 14:00:18,294][__main__][INFO] - Starting training!
[2024-01-31 14:00:25,811][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 97, in step
    p.add_(momentum, alpha=-group['lr'])
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
[2024-01-31 14:00:25,818][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_13-59-41
[2024-01-31 14:00:25,818][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 14:01:53,448][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 14:01:53,462][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 14:01:53,577][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 14:01:53,585][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 14:01:53,608][__main__][INFO] - Instantiating callbacks...
[2024-01-31 14:01:53,608][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 14:01:53,614][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 14:01:53,616][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 14:01:53,617][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 14:01:53,621][__main__][INFO] - Instantiating loggers...
[2024-01-31 14:01:53,621][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 14:02:38,647][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 14:02:39,340][__main__][INFO] - Logging hyperparameters!
[2024-01-31 14:02:39,343][__main__][INFO] - Starting training!
[2024-01-31 14:02:46,578][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 97, in step
    p.add_(momentum, alpha=-group['lr'])
RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.
[2024-01-31 14:02:46,585][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-01-31_14-01-53
[2024-01-31 14:02:46,585][src.utils.utils][INFO] - Closing wandb!
[2024-01-31 14:03:26,274][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-01-31 14:03:26,282][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-01-31 14:03:26,380][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-01-31 14:03:26,386][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-01-31 14:03:26,413][__main__][INFO] - Instantiating callbacks...
[2024-01-31 14:03:26,413][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-01-31 14:03:26,418][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-01-31 14:03:26,421][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-01-31 14:03:26,423][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-01-31 14:03:26,424][__main__][INFO] - Instantiating loggers...
[2024-01-31 14:03:26,425][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-01-31 14:04:00,114][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-01-31 14:04:00,807][__main__][INFO] - Logging hyperparameters!
[2024-01-31 14:04:00,809][__main__][INFO] - Starting training!
[2024-01-31 14:05:49,703][__main__][INFO] - Starting testing!
[2024-02-01 21:08:08,175][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-01 21:08:08,192][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-01 21:08:08,283][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-01 21:08:08,289][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-01 21:08:08,355][__main__][INFO] - Instantiating callbacks...
[2024-02-01 21:08:08,355][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-01 21:08:08,357][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-01 21:08:08,362][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-01 21:08:08,362][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-01 21:08:08,365][__main__][INFO] - Instantiating loggers...
[2024-02-01 21:08:08,365][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-01 21:08:56,866][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-01 21:08:57,605][__main__][INFO] - Logging hyperparameters!
[2024-02-01 21:08:57,613][__main__][INFO] - Starting training!
[2024-02-01 21:19:54,604][__main__][INFO] - Starting testing!
[2024-02-01 21:20:02,107][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-01_21-08-08\checkpoints\epoch_008.ckpt
[2024-02-01 21:20:02,109][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-01_21-08-08
[2024-02-01 21:20:02,110][src.utils.utils][INFO] - Closing wandb!
[2024-02-01 21:20:28,513][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-01 21:50:47,650][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-01 21:50:47,663][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-01 21:50:47,823][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-01 21:50:47,831][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-01 21:50:47,858][__main__][INFO] - Instantiating callbacks...
[2024-02-01 21:50:47,858][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-01 21:50:47,865][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-01 21:50:47,868][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-01 21:50:47,868][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-01 21:50:47,873][__main__][INFO] - Instantiating loggers...
[2024-02-01 21:50:47,873][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-01 21:51:19,298][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-01 21:51:19,935][__main__][INFO] - Logging hyperparameters!
[2024-02-01 21:51:19,938][__main__][INFO] - Starting training!
[2024-02-01 22:00:20,843][__main__][INFO] - Starting testing!
[2024-02-01 22:00:26,919][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-01_21-50-47\checkpoints\epoch_007.ckpt
[2024-02-01 22:00:26,924][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-01_21-50-47
[2024-02-01 22:00:26,926][src.utils.utils][INFO] - Closing wandb!
[2024-02-01 22:01:01,427][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-03 11:14:56,617][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 11:14:56,627][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 11:14:56,715][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 11:14:56,721][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 11:14:56,777][__main__][INFO] - Instantiating callbacks...
[2024-02-03 11:14:56,778][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 11:14:56,783][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 11:14:56,784][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 11:14:56,785][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 11:14:56,786][__main__][INFO] - Instantiating loggers...
[2024-02-03 11:14:56,787][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 11:15:45,607][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 11:15:46,402][__main__][INFO] - Logging hyperparameters!
[2024-02-03 11:15:46,408][__main__][INFO] - Starting training!
[2024-02-03 11:24:53,190][__main__][INFO] - Starting testing!
[2024-02-03 11:25:00,598][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_11-14-56\checkpoints\epoch_008.ckpt
[2024-02-03 11:25:00,599][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_11-14-56
[2024-02-03 11:25:00,600][src.utils.utils][INFO] - Closing wandb!
[2024-02-03 11:25:22,913][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-03 20:23:22,529][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 20:23:22,536][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 20:23:22,619][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 20:23:22,625][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 20:23:22,717][__main__][INFO] - Instantiating callbacks...
[2024-02-03 20:23:22,717][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 20:23:22,721][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 20:23:22,723][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 20:23:22,723][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 20:23:22,724][__main__][INFO] - Instantiating loggers...
[2024-02-03 20:23:22,724][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 20:23:52,474][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 20:23:53,114][__main__][INFO] - Logging hyperparameters!
[2024-02-03 20:23:53,117][__main__][INFO] - Starting training!
[2024-02-03 20:24:05,097][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 66, in step
    x = torch.tensor(len(curvature_avg), requires_grad=True)
RuntimeError: Only Tensors of floating point and complex dtype can require gradients
[2024-02-03 20:24:05,105][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_20-23-22
[2024-02-03 20:24:05,106][src.utils.utils][INFO] - Closing wandb!
[2024-02-03 20:25:58,143][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 20:25:58,153][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 20:25:58,249][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 20:25:58,254][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 20:25:58,277][__main__][INFO] - Instantiating callbacks...
[2024-02-03 20:25:58,277][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 20:25:58,283][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 20:25:58,285][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 20:25:58,286][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 20:25:58,288][__main__][INFO] - Instantiating loggers...
[2024-02-03 20:25:58,288][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 20:26:29,286][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 20:26:29,966][__main__][INFO] - Logging hyperparameters!
[2024-02-03 20:26:29,969][__main__][INFO] - Starting training!
[2024-02-03 20:26:36,165][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 67, in step
    derivative_approximation = torch.autograd.grad(y_values, x)[0].item()
  File "D:\Anaconda3\lib\site-packages\torch\autograd\__init__.py", line 303, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
[2024-02-03 20:26:36,170][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_20-25-58
[2024-02-03 20:26:36,170][src.utils.utils][INFO] - Closing wandb!
[2024-02-03 20:28:08,878][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 20:28:08,885][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 20:28:08,976][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 20:28:08,980][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 20:28:08,998][__main__][INFO] - Instantiating callbacks...
[2024-02-03 20:28:08,999][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 20:28:09,003][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 20:28:09,005][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 20:28:09,005][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 20:28:09,006][__main__][INFO] - Instantiating loggers...
[2024-02-03 20:28:09,007][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 20:28:36,267][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 20:28:36,888][__main__][INFO] - Logging hyperparameters!
[2024-02-03 20:28:36,890][__main__][INFO] - Starting training!
[2024-02-03 20:28:42,981][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 68, in step
    derivative_approximation = torch.autograd.grad(y_values, x)[0].item()
  File "D:\Anaconda3\lib\site-packages\torch\autograd\__init__.py", line 288, in grad
    grad_outputs_ = _make_grads(t_outputs, grad_outputs_, is_grads_batched=is_grads_batched)
  File "D:\Anaconda3\lib\site-packages\torch\autograd\__init__.py", line 88, in _make_grads
    raise RuntimeError("grad can be implicitly created only for scalar outputs")
RuntimeError: grad can be implicitly created only for scalar outputs
[2024-02-03 20:28:42,985][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_20-28-08
[2024-02-03 20:28:42,986][src.utils.utils][INFO] - Closing wandb!
[2024-02-03 20:30:26,373][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 20:30:26,381][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 20:30:26,468][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 20:30:26,472][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 20:30:26,491][__main__][INFO] - Instantiating callbacks...
[2024-02-03 20:30:26,491][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 20:30:26,495][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 20:30:26,496][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 20:30:26,497][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 20:30:26,498][__main__][INFO] - Instantiating loggers...
[2024-02-03 20:30:26,498][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 20:30:55,678][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 20:30:56,329][__main__][INFO] - Logging hyperparameters!
[2024-02-03 20:30:56,332][__main__][INFO] - Starting training!
[2024-02-03 20:31:02,381][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 70, in step
    derivative_approximation = torch.autograd.grad(interpolated_value, x)[0].item()
  File "D:\Anaconda3\lib\site-packages\torch\autograd\__init__.py", line 288, in grad
    grad_outputs_ = _make_grads(t_outputs, grad_outputs_, is_grads_batched=is_grads_batched)
  File "D:\Anaconda3\lib\site-packages\torch\autograd\__init__.py", line 88, in _make_grads
    raise RuntimeError("grad can be implicitly created only for scalar outputs")
RuntimeError: grad can be implicitly created only for scalar outputs
[2024-02-03 20:31:02,385][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_20-30-26
[2024-02-03 20:31:02,386][src.utils.utils][INFO] - Closing wandb!
[2024-02-03 20:33:06,456][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 20:33:06,463][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 20:33:06,545][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 20:33:06,550][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 20:33:06,568][__main__][INFO] - Instantiating callbacks...
[2024-02-03 20:33:06,568][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 20:33:06,572][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 20:33:06,573][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 20:33:06,574][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 20:33:06,575][__main__][INFO] - Instantiating loggers...
[2024-02-03 20:33:06,575][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 20:33:36,215][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 20:33:36,983][__main__][INFO] - Logging hyperparameters!
[2024-02-03 20:33:36,985][__main__][INFO] - Starting training!
[2024-02-03 20:33:44,791][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 60, in step
    p.data.add_(-step_size * derivative_approximation, grad)
TypeError: add_() takes 1 positional argument but 2 were given
[2024-02-03 20:33:44,796][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_20-33-06
[2024-02-03 20:33:44,797][src.utils.utils][INFO] - Closing wandb!
[2024-02-03 20:34:23,984][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 20:34:23,992][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 20:34:24,083][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 20:34:24,088][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 20:34:24,107][__main__][INFO] - Instantiating callbacks...
[2024-02-03 20:34:24,108][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 20:34:24,113][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 20:34:24,115][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 20:34:24,115][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 20:34:24,117][__main__][INFO] - Instantiating loggers...
[2024-02-03 20:34:24,117][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 20:34:51,101][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 20:34:51,540][__main__][INFO] - Logging hyperparameters!
[2024-02-03 20:34:51,544][__main__][INFO] - Starting training!
[2024-02-03 20:34:57,589][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 62, in step
    p.data.add_(-step_size * derivative_approximation, grad)
TypeError: add_() takes 1 positional argument but 2 were given
[2024-02-03 20:34:57,592][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_20-34-23
[2024-02-03 20:34:57,594][src.utils.utils][INFO] - Closing wandb!
[2024-02-03 20:35:48,668][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 20:35:48,677][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 20:35:48,756][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 20:35:48,761][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 20:35:48,776][__main__][INFO] - Instantiating callbacks...
[2024-02-03 20:35:48,776][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 20:35:48,780][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 20:35:48,782][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 20:35:48,782][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 20:35:48,784][__main__][INFO] - Instantiating loggers...
[2024-02-03 20:35:48,784][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 20:36:17,893][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 20:36:18,467][__main__][INFO] - Logging hyperparameters!
[2024-02-03 20:36:18,471][__main__][INFO] - Starting training!
[2024-02-03 20:36:24,547][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 62, in step
    p.data.add_(-step_size * derivative_approximation, grad)
TypeError: add_() takes 1 positional argument but 2 were given
[2024-02-03 20:36:24,551][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-03_20-35-48
[2024-02-03 20:36:24,551][src.utils.utils][INFO] - Closing wandb!
[2024-02-03 20:37:09,003][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-03 20:37:09,009][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-03 20:37:09,081][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-03 20:37:09,085][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-03 20:37:09,103][__main__][INFO] - Instantiating callbacks...
[2024-02-03 20:37:09,103][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-03 20:37:09,107][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-03 20:37:09,108][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-03 20:37:09,110][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-03 20:37:09,111][__main__][INFO] - Instantiating loggers...
[2024-02-03 20:37:09,111][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-03 20:37:38,946][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-03 20:37:39,370][__main__][INFO] - Logging hyperparameters!
[2024-02-03 20:37:39,373][__main__][INFO] - Starting training!
[2024-02-03 20:38:45,543][__main__][INFO] - Starting testing!
[2024-02-04 16:24:19,874][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 16:24:19,890][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 16:24:20,047][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 16:24:20,058][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 16:24:20,141][__main__][INFO] - Instantiating callbacks...
[2024-02-04 16:24:20,141][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 16:24:20,152][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 16:24:20,154][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 16:24:20,155][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 16:24:20,158][__main__][INFO] - Instantiating loggers...
[2024-02-04 16:24:20,159][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 16:25:02,622][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 16:25:03,543][__main__][INFO] - Logging hyperparameters!
[2024-02-04 16:25:03,548][__main__][INFO] - Starting training!
[2024-02-04 16:25:19,695][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 64, in step
    p.data.addcdiv_(-step_size, corrected_exp_avg, denom)
TypeError: addcdiv_() takes 2 positional arguments but 3 were given
[2024-02-04 16:25:19,712][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-04_16-24-19
[2024-02-04 16:25:19,713][src.utils.utils][INFO] - Closing wandb!
[2024-02-04 16:27:04,351][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 16:27:04,358][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 16:27:04,436][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 16:27:04,441][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 16:27:04,459][__main__][INFO] - Instantiating callbacks...
[2024-02-04 16:27:04,459][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 16:27:04,466][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 16:27:04,468][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 16:27:04,469][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 16:27:04,471][__main__][INFO] - Instantiating loggers...
[2024-02-04 16:27:04,471][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 16:27:37,085][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 16:27:37,942][__main__][INFO] - Logging hyperparameters!
[2024-02-04 16:27:37,949][__main__][INFO] - Starting training!
[2024-02-04 16:27:49,961][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 64, in step
    p.data.addcdiv_(-step_size, corrected_exp_avg, denom)
TypeError: addcdiv_() takes 2 positional arguments but 3 were given
[2024-02-04 16:27:49,968][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-04_16-27-04
[2024-02-04 16:27:49,969][src.utils.utils][INFO] - Closing wandb!
[2024-02-04 16:28:31,578][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 16:28:31,585][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 16:28:31,691][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 16:28:31,697][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 16:28:31,715][__main__][INFO] - Instantiating callbacks...
[2024-02-04 16:28:31,715][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 16:28:31,720][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 16:28:31,722][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 16:28:31,724][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 16:28:31,725][__main__][INFO] - Instantiating loggers...
[2024-02-04 16:28:31,725][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 16:29:02,707][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 16:29:03,422][__main__][INFO] - Logging hyperparameters!
[2024-02-04 16:29:03,425][__main__][INFO] - Starting training!
[2024-02-04 16:29:09,820][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 64, in step
    p.data.addcdiv_(-step_size, corrected_exp_avg, denom)
TypeError: addcdiv_() takes 2 positional arguments but 3 were given
[2024-02-04 16:29:09,825][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-04_16-28-31
[2024-02-04 16:29:09,825][src.utils.utils][INFO] - Closing wandb!
[2024-02-04 16:29:59,994][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 16:30:00,016][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 16:30:00,162][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 16:30:00,168][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 16:30:00,188][__main__][INFO] - Instantiating callbacks...
[2024-02-04 16:30:00,190][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 16:30:00,196][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 16:30:00,198][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 16:30:00,199][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 16:30:00,200][__main__][INFO] - Instantiating loggers...
[2024-02-04 16:30:00,200][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 16:30:33,030][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 16:30:34,570][__main__][INFO] - Logging hyperparameters!
[2024-02-04 16:30:34,581][__main__][INFO] - Starting training!
[2024-02-04 16:30:47,496][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 64, in step
    p.data.addcdiv_(-step_size, corrected_exp_avg, denom)
TypeError: addcdiv_() takes 2 positional arguments but 3 were given
[2024-02-04 16:30:47,511][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-04_16-29-59
[2024-02-04 16:30:47,512][src.utils.utils][INFO] - Closing wandb!
[2024-02-04 16:33:23,854][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 16:33:23,861][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 16:33:23,955][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 16:33:23,962][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 16:33:23,982][__main__][INFO] - Instantiating callbacks...
[2024-02-04 16:33:23,984][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 16:33:23,988][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 16:33:23,989][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 16:33:23,990][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 16:33:23,991][__main__][INFO] - Instantiating loggers...
[2024-02-04 16:33:23,991][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 16:33:53,844][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 16:33:54,385][__main__][INFO] - Logging hyperparameters!
[2024-02-04 16:33:54,388][__main__][INFO] - Starting training!
[2024-02-04 16:34:55,902][__main__][INFO] - Starting testing!
[2024-02-04 20:18:49,173][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:18:49,182][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:18:49,269][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:18:49,277][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:18:49,363][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:18:49,363][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:18:49,366][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:18:49,371][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:18:49,371][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:18:49,371][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:18:49,371][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:19:26,061][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:19:26,827][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:19:26,833][__main__][INFO] - Starting training!
[2024-02-04 20:20:35,549][__main__][INFO] - Starting testing!
[2024-02-04 20:22:11,396][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:22:11,406][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:22:11,516][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:22:11,522][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:22:11,550][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:22:11,550][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:22:11,559][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:22:11,561][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:22:11,562][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:22:11,562][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:22:11,562][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:22:47,831][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:22:48,616][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:22:48,621][__main__][INFO] - Starting training!
[2024-02-04 20:23:53,326][__main__][INFO] - Starting testing!
[2024-02-04 20:24:59,378][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:24:59,391][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:24:59,499][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:24:59,508][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:24:59,544][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:24:59,544][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:24:59,550][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:24:59,553][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:24:59,554][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:24:59,556][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:24:59,556][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:25:40,488][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:25:41,045][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:25:41,052][__main__][INFO] - Starting training!
[2024-02-04 20:26:44,948][__main__][INFO] - Starting testing!
[2024-02-04 20:27:23,595][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:27:23,609][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:27:23,708][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:27:23,716][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:27:23,749][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:27:23,749][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:27:23,755][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:27:23,758][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:27:23,758][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:27:23,758][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:27:23,758][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:28:02,470][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:28:03,207][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:28:03,210][__main__][INFO] - Starting training!
[2024-02-04 20:29:12,485][__main__][INFO] - Starting testing!
[2024-02-04 20:29:53,915][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:29:53,927][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:29:54,009][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:29:54,017][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:29:54,046][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:29:54,048][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:29:54,054][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:29:54,056][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:29:54,056][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:29:54,056][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:29:54,056][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:30:31,128][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:30:31,844][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:30:31,847][__main__][INFO] - Starting training!
[2024-02-04 20:31:32,485][__main__][INFO] - Starting testing!
[2024-02-04 20:32:37,804][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:32:37,812][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:32:37,886][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:32:37,902][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:32:37,928][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:32:37,934][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:32:37,936][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:32:37,940][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:32:37,940][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:32:37,940][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:32:37,940][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:33:14,917][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:33:15,674][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:33:15,679][__main__][INFO] - Starting training!
[2024-02-04 20:34:13,693][__main__][INFO] - Starting testing!
[2024-02-04 20:34:51,258][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:34:51,273][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:34:51,364][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:34:51,369][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:34:51,389][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:34:51,389][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:34:51,399][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:34:51,401][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:34:51,403][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:34:51,405][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:34:51,405][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:35:33,663][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:35:34,413][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:35:34,419][__main__][INFO] - Starting training!
[2024-02-04 20:35:46,068][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 53, in step
    self.update_learning_rate()
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 75, in update_learning_rate
    group['lr'] = self.lr
AttributeError: 'AWD' object has no attribute 'lr'
[2024-02-04 20:35:46,079][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-04_20-34-51
[2024-02-04 20:35:46,079][src.utils.utils][INFO] - Closing wandb!
[2024-02-04 20:36:57,174][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:36:57,182][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:36:57,264][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:36:57,273][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:36:57,300][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:36:57,300][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:36:57,304][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:36:57,304][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:36:57,309][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:36:57,309][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:36:57,309][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:37:33,756][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:37:34,684][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:37:34,687][__main__][INFO] - Starting training!
[2024-02-04 20:40:03,570][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:40:03,584][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:40:03,727][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:40:03,739][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:40:03,802][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:40:03,802][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:40:03,811][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:40:03,813][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:40:03,814][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:40:03,818][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:40:03,819][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:40:48,392][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:40:49,742][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:40:49,745][__main__][INFO] - Starting training!
[2024-02-04 20:41:38,375][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:41:38,384][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:41:38,539][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:41:38,555][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:41:38,632][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:41:38,632][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:41:38,642][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:41:38,647][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:41:38,647][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:41:38,652][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:41:38,652][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:42:30,714][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:42:31,364][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:42:31,365][__main__][INFO] - Starting training!
[2024-02-04 20:43:36,505][__main__][INFO] - Starting testing!
[2024-02-04 20:44:24,441][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:44:24,441][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:44:24,563][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:44:24,567][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:44:24,591][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:44:24,596][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:44:24,601][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:44:24,601][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:44:24,601][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:44:24,605][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:44:24,605][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:45:14,574][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:45:15,177][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:45:15,181][__main__][INFO] - Starting training!
[2024-02-04 20:46:10,959][__main__][INFO] - Starting testing!
[2024-02-04 20:47:01,211][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:47:01,219][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:47:01,334][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:47:01,343][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:47:01,384][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:47:01,384][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:47:01,392][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:47:01,392][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:47:01,392][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:47:01,392][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:47:01,392][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:47:34,368][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:47:35,148][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:47:35,153][__main__][INFO] - Starting training!
[2024-02-04 20:48:31,829][__main__][INFO] - Starting testing!
[2024-02-04 20:49:12,951][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:49:12,964][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:49:13,069][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:49:13,079][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:49:13,111][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:49:13,113][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:49:13,115][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:49:13,120][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:49:13,120][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:49:13,123][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:49:13,124][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:49:48,404][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:49:49,314][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:49:49,318][__main__][INFO] - Starting training!
[2024-02-04 20:50:44,040][__main__][INFO] - Starting testing!
[2024-02-04 20:52:19,388][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:52:19,396][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:52:19,510][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:52:19,522][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:52:19,561][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:52:19,561][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:52:19,570][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:52:19,573][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:52:19,574][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:52:19,574][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:52:19,574][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:52:59,724][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:53:00,496][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:53:00,499][__main__][INFO] - Starting training!
[2024-02-04 20:53:08,893][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 76, in step
    self.update_learning_rate()
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 101, in update_learning_rate
    self.exp_avg_sq_biased.mul_(self.alpha).add_(1 - self.alpha, exp_avg_sq_hat)
NameError: name 'exp_avg_sq_hat' is not defined
[2024-02-04 20:53:08,906][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-04_20-52-19
[2024-02-04 20:53:08,906][src.utils.utils][INFO] - Closing wandb!
[2024-02-04 20:55:22,364][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:55:22,371][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:55:22,471][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:55:22,475][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:55:22,494][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:55:22,494][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:55:22,498][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:55:22,498][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:55:22,498][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:55:22,503][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:55:22,503][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:55:54,393][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:55:54,936][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:55:54,939][__main__][INFO] - Starting training!
[2024-02-04 20:57:07,559][__main__][INFO] - Starting testing!
[2024-02-04 20:58:01,028][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 20:58:01,037][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 20:58:01,145][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 20:58:01,147][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 20:58:01,170][__main__][INFO] - Instantiating callbacks...
[2024-02-04 20:58:01,170][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 20:58:01,176][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 20:58:01,178][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 20:58:01,179][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 20:58:01,180][__main__][INFO] - Instantiating loggers...
[2024-02-04 20:58:01,180][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 20:58:28,273][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 20:58:28,902][__main__][INFO] - Logging hyperparameters!
[2024-02-04 20:58:28,906][__main__][INFO] - Starting training!
[2024-02-04 21:00:10,460][__main__][INFO] - Starting testing!
[2024-02-04 21:02:29,876][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:02:29,886][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:02:29,997][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:02:30,002][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:02:30,029][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:02:30,029][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:02:30,037][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:02:30,039][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:02:30,041][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:02:30,041][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:02:30,041][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:03:06,565][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:03:07,373][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:03:07,376][__main__][INFO] - Starting training!
[2024-02-04 21:04:52,562][__main__][INFO] - Starting testing!
[2024-02-04 21:05:32,858][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:05:32,873][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:05:33,046][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:05:33,051][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:05:33,067][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:05:33,067][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:05:33,076][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:05:33,076][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:05:33,076][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:05:33,081][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:05:33,081][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:06:04,958][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:06:05,559][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:06:05,565][__main__][INFO] - Starting training!
[2024-02-04 21:07:36,660][__main__][INFO] - Starting testing!
[2024-02-04 21:10:07,231][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:10:07,237][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:10:07,329][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:10:07,334][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:10:07,358][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:10:07,359][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:10:07,364][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:10:07,365][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:10:07,366][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:10:07,368][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:10:07,368][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:10:41,232][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:10:41,908][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:10:41,913][__main__][INFO] - Starting training!
[2024-02-04 21:11:37,126][__main__][INFO] - Starting testing!
[2024-02-04 21:15:19,218][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:15:19,227][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:15:19,303][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:15:19,308][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:15:19,326][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:15:19,327][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:15:19,332][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:15:19,333][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:15:19,333][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:15:19,334][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:15:19,335][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:15:49,280][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:15:49,988][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:15:49,992][__main__][INFO] - Starting training!
[2024-02-04 21:16:51,670][__main__][INFO] - Starting testing!
[2024-02-04 21:19:01,939][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:19:01,946][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:19:02,024][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:19:02,028][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:19:02,047][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:19:02,048][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:19:02,051][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:19:02,052][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:19:02,052][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:19:02,053][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:19:02,054][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:19:33,374][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:19:33,952][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:19:33,964][__main__][INFO] - Starting training!
[2024-02-04 21:20:40,760][__main__][INFO] - Starting testing!
[2024-02-04 21:26:48,160][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:26:48,167][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:26:48,247][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:26:48,252][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:26:48,269][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:26:48,270][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:26:48,273][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:26:48,274][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:26:48,275][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:26:48,275][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:26:48,277][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:27:18,711][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:27:19,299][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:27:19,307][__main__][INFO] - Starting training!
[2024-02-04 21:28:25,877][__main__][INFO] - Starting testing!
[2024-02-04 21:47:51,509][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:47:51,518][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:47:51,621][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:47:51,629][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:47:51,653][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:47:51,654][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:47:51,660][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:47:51,662][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:47:51,663][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:47:51,665][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:47:51,666][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:48:32,511][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:48:33,144][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:48:33,147][__main__][INFO] - Starting training!
[2024-02-04 21:49:25,113][__main__][INFO] - Starting testing!
[2024-02-04 21:50:05,312][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:50:05,316][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:50:05,393][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:50:05,398][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:50:05,417][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:50:05,417][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:50:05,424][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:50:05,428][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:50:05,428][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:50:05,428][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:50:05,428][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:50:32,719][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:50:33,389][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:50:33,395][__main__][INFO] - Starting training!
[2024-02-04 21:51:25,329][__main__][INFO] - Starting testing!
[2024-02-04 21:52:21,449][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 21:52:21,457][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 21:52:21,543][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 21:52:21,545][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 21:52:21,565][__main__][INFO] - Instantiating callbacks...
[2024-02-04 21:52:21,569][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 21:52:21,573][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 21:52:21,573][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 21:52:21,573][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 21:52:21,573][__main__][INFO] - Instantiating loggers...
[2024-02-04 21:52:21,573][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 21:52:52,221][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 21:52:52,821][__main__][INFO] - Logging hyperparameters!
[2024-02-04 21:52:52,823][__main__][INFO] - Starting training!
[2024-02-04 21:53:33,809][__main__][INFO] - Starting testing!
[2024-02-04 22:02:11,979][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-04 22:02:11,983][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-04 22:02:12,055][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-04 22:02:12,061][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-04 22:02:12,081][__main__][INFO] - Instantiating callbacks...
[2024-02-04 22:02:12,081][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-04 22:02:12,083][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-04 22:02:12,083][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-04 22:02:12,087][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-04 22:02:12,087][__main__][INFO] - Instantiating loggers...
[2024-02-04 22:02:12,087][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-04 22:02:40,060][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-04 22:02:40,674][__main__][INFO] - Logging hyperparameters!
[2024-02-04 22:02:40,678][__main__][INFO] - Starting training!
[2024-02-04 22:03:45,877][__main__][INFO] - Starting testing!
[2024-02-05 19:33:44,231][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-05 19:33:44,242][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-05 19:33:44,366][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-05 19:33:44,373][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-05 19:33:44,427][__main__][INFO] - Instantiating callbacks...
[2024-02-05 19:33:44,427][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-05 19:33:44,432][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-05 19:33:44,434][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-05 19:33:44,435][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-05 19:33:44,437][__main__][INFO] - Instantiating loggers...
[2024-02-05 19:33:44,437][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-05 19:34:14,751][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-05 19:34:15,391][__main__][INFO] - Logging hyperparameters!
[2024-02-05 19:34:15,394][__main__][INFO] - Starting training!
[2024-02-05 19:36:39,080][__main__][INFO] - Starting testing!
[2024-02-05 19:36:45,574][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-05_19-33-44\checkpoints\epoch_004.ckpt
[2024-02-05 19:36:45,576][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-05_19-33-44
[2024-02-05 19:36:45,576][src.utils.utils][INFO] - Closing wandb!
[2024-02-05 19:37:00,199][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-05 19:42:14,139][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-05 19:42:14,146][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-05 19:42:14,229][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-05 19:42:14,234][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-05 19:42:14,252][__main__][INFO] - Instantiating callbacks...
[2024-02-05 19:42:14,253][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-05 19:42:14,259][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-05 19:42:14,262][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-05 19:42:14,263][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-05 19:42:14,264][__main__][INFO] - Instantiating loggers...
[2024-02-05 19:42:14,265][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-05 19:42:46,443][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-05 19:42:47,113][__main__][INFO] - Logging hyperparameters!
[2024-02-05 19:42:47,117][__main__][INFO] - Starting training!
[2024-02-05 19:51:48,261][__main__][INFO] - Starting testing!
[2024-02-05 19:51:54,231][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-05_19-42-14\checkpoints\epoch_008.ckpt
[2024-02-05 19:51:54,233][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-05_19-42-14
[2024-02-05 19:51:54,234][src.utils.utils][INFO] - Closing wandb!
[2024-02-05 19:52:17,631][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-05 19:52:52,800][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-05 19:52:52,807][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-05 19:52:52,888][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-05 19:52:52,893][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-05 19:52:52,912][__main__][INFO] - Instantiating callbacks...
[2024-02-05 19:52:52,912][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-05 19:52:52,915][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-05 19:52:52,917][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-05 19:52:52,917][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-05 19:52:52,919][__main__][INFO] - Instantiating loggers...
[2024-02-05 19:52:52,919][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-05 19:53:19,739][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-05 19:53:20,335][__main__][INFO] - Logging hyperparameters!
[2024-02-05 19:53:20,338][__main__][INFO] - Starting training!
[2024-02-05 19:55:24,161][__main__][INFO] - Starting testing!
[2024-02-05 19:55:41,428][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-05 19:55:41,436][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-05 19:55:41,529][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-05 19:55:41,534][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-05 19:55:41,554][__main__][INFO] - Instantiating callbacks...
[2024-02-05 19:55:41,556][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-05 19:55:41,559][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-05 19:55:41,561][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-05 19:55:41,562][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-05 19:55:41,563][__main__][INFO] - Instantiating loggers...
[2024-02-05 19:55:41,563][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-05 19:56:13,399][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-05 19:56:14,142][__main__][INFO] - Logging hyperparameters!
[2024-02-05 19:56:14,144][__main__][INFO] - Starting training!
[2024-02-05 19:57:49,259][__main__][INFO] - Starting testing!
[2024-02-05 19:58:15,726][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-05 19:58:15,734][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-05 19:58:15,818][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-05 19:58:15,823][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-05 19:58:15,843][__main__][INFO] - Instantiating callbacks...
[2024-02-05 19:58:15,844][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-05 19:58:15,847][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-05 19:58:15,849][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-05 19:58:15,850][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-05 19:58:15,851][__main__][INFO] - Instantiating loggers...
[2024-02-05 19:58:15,852][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-05 19:58:48,324][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-05 19:58:49,007][__main__][INFO] - Logging hyperparameters!
[2024-02-05 19:58:49,010][__main__][INFO] - Starting training!
[2024-02-05 20:09:35,302][__main__][INFO] - Starting testing!
[2024-02-05 20:09:40,826][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-05_19-58-15\checkpoints\epoch_014.ckpt
[2024-02-05 20:09:40,828][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-05_19-58-15
[2024-02-05 20:09:40,828][src.utils.utils][INFO] - Closing wandb!
[2024-02-05 20:10:03,893][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-07 13:39:37,163][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-07 13:39:37,185][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-07 13:39:37,413][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-07 13:39:37,433][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-07 13:39:37,525][__main__][INFO] - Instantiating callbacks...
[2024-02-07 13:39:37,526][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-07 13:39:37,537][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-07 13:39:37,541][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-07 13:39:37,543][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-07 13:39:37,549][__main__][INFO] - Instantiating loggers...
[2024-02-07 13:39:37,550][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-07 13:40:28,342][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-07 13:40:31,781][__main__][INFO] - Logging hyperparameters!
[2024-02-07 13:40:31,791][__main__][INFO] - Starting training!
[2024-02-07 13:52:08,913][__main__][INFO] - Starting testing!
[2024-02-07 13:52:18,226][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_13-39-36\checkpoints\epoch_009.ckpt
[2024-02-07 13:52:18,229][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_13-39-36
[2024-02-07 13:52:18,229][src.utils.utils][INFO] - Closing wandb!
[2024-02-07 13:53:14,395][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-07 13:53:14,405][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-07 13:53:14,524][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-07 13:53:14,533][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-07 13:53:14,561][__main__][INFO] - Instantiating callbacks...
[2024-02-07 13:53:14,562][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-07 13:53:14,568][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-07 13:53:14,571][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-07 13:53:14,573][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-07 13:53:14,576][__main__][INFO] - Instantiating loggers...
[2024-02-07 13:53:14,577][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-07 13:53:57,546][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-07 13:54:00,161][__main__][INFO] - Logging hyperparameters!
[2024-02-07 13:54:00,167][__main__][INFO] - Starting training!
[2024-02-07 14:02:33,224][__main__][INFO] - Starting testing!
[2024-02-07 14:02:39,538][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_13-53-14\checkpoints\epoch_018.ckpt
[2024-02-07 14:02:39,541][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_13-53-14
[2024-02-07 14:02:39,541][src.utils.utils][INFO] - Closing wandb!
[2024-02-07 14:04:44,828][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-07 14:04:44,840][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-07 14:04:44,928][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-07 14:04:44,939][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-07 14:04:44,960][__main__][INFO] - Instantiating callbacks...
[2024-02-07 14:04:44,962][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-07 14:04:44,969][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-07 14:04:44,973][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-07 14:04:44,974][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-07 14:04:44,977][__main__][INFO] - Instantiating loggers...
[2024-02-07 14:04:44,978][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-07 14:05:27,931][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-07 14:05:31,654][__main__][INFO] - Logging hyperparameters!
[2024-02-07 14:05:31,664][__main__][INFO] - Starting training!
[2024-02-07 14:13:26,299][__main__][INFO] - Starting testing!
[2024-02-07 14:13:32,656][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_14-04-44\checkpoints\epoch_019.ckpt
[2024-02-07 14:13:32,659][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_14-04-44
[2024-02-07 14:13:32,661][src.utils.utils][INFO] - Closing wandb!
[2024-02-07 14:16:10,098][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-07 14:16:10,115][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-07 14:16:10,296][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-07 14:16:10,310][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-07 14:16:10,360][__main__][INFO] - Instantiating callbacks...
[2024-02-07 14:16:10,361][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-07 14:16:10,372][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-07 14:16:10,375][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-07 14:16:10,377][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-07 14:16:10,380][__main__][INFO] - Instantiating loggers...
[2024-02-07 14:16:10,381][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-07 14:16:49,721][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-07 14:16:51,793][__main__][INFO] - Logging hyperparameters!
[2024-02-07 14:16:51,798][__main__][INFO] - Starting training!
[2024-02-07 14:26:56,651][__main__][INFO] - Starting testing!
[2024-02-07 14:27:02,150][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_14-16-09\checkpoints\epoch_010.ckpt
[2024-02-07 14:27:02,152][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_14-16-09
[2024-02-07 14:27:02,153][src.utils.utils][INFO] - Closing wandb!
[2024-02-07 14:44:26,782][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-07 14:44:26,789][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-07 14:44:26,869][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-07 14:44:26,875][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-07 14:44:26,892][__main__][INFO] - Instantiating callbacks...
[2024-02-07 14:44:26,892][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-07 14:44:26,896][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-07 14:44:26,898][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-07 14:44:26,899][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-07 14:44:26,902][__main__][INFO] - Instantiating loggers...
[2024-02-07 14:44:26,902][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-07 14:44:57,104][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-07 14:44:58,172][__main__][INFO] - Logging hyperparameters!
[2024-02-07 14:44:58,175][__main__][INFO] - Starting training!
[2024-02-07 14:51:01,334][__main__][INFO] - Starting testing!
[2024-02-07 14:51:29,965][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-07 14:51:29,977][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-07 14:51:30,088][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-07 14:51:30,097][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-07 14:51:30,126][__main__][INFO] - Instantiating callbacks...
[2024-02-07 14:51:30,127][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-07 14:51:30,133][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-07 14:51:30,135][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-07 14:51:30,137][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-07 14:51:30,141][__main__][INFO] - Instantiating loggers...
[2024-02-07 14:51:30,141][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-07 14:52:14,463][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-07 14:52:17,113][__main__][INFO] - Logging hyperparameters!
[2024-02-07 14:52:17,123][__main__][INFO] - Starting training!
[2024-02-07 14:55:41,081][__main__][INFO] - Starting testing!
[2024-02-07 14:57:34,826][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-07 14:57:34,835][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-07 14:57:34,933][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-07 14:57:34,941][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-07 14:57:34,969][__main__][INFO] - Instantiating callbacks...
[2024-02-07 14:57:34,969][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-07 14:57:34,974][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-07 14:57:34,976][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-07 14:57:34,977][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-07 14:57:34,979][__main__][INFO] - Instantiating loggers...
[2024-02-07 14:57:34,980][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-07 14:58:06,103][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-07 14:58:07,279][__main__][INFO] - Logging hyperparameters!
[2024-02-07 14:58:07,282][__main__][INFO] - Starting training!
[2024-02-07 14:59:03,302][__main__][INFO] - Starting testing!
[2024-02-07 14:59:09,022][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_14-57-34\checkpoints\epoch_001.ckpt
[2024-02-07 14:59:09,024][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-07_14-57-34
[2024-02-07 14:59:09,025][src.utils.utils][INFO] - Closing wandb!
[2024-02-18 13:44:02,961][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-18 13:44:02,976][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-18 13:44:03,142][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-18 13:44:03,157][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-18 13:44:03,272][__main__][INFO] - Instantiating callbacks...
[2024-02-18 13:44:03,273][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-18 13:44:03,281][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-18 13:44:03,285][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-18 13:44:03,286][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-18 13:44:03,291][__main__][INFO] - Instantiating loggers...
[2024-02-18 13:44:03,291][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-18 13:44:47,454][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-18 13:44:49,207][__main__][INFO] - Logging hyperparameters!
[2024-02-18 13:44:49,213][__main__][INFO] - Starting training!
[2024-02-18 13:47:10,157][__main__][INFO] - Starting testing!
[2024-02-18 13:51:59,681][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-18 13:51:59,689][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-18 13:51:59,770][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-18 13:51:59,776][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-18 13:51:59,911][__main__][INFO] - Instantiating callbacks...
[2024-02-18 13:51:59,912][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-18 13:51:59,918][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-18 13:51:59,920][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-18 13:51:59,921][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-18 13:51:59,924][__main__][INFO] - Instantiating loggers...
[2024-02-18 13:51:59,924][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-18 13:52:33,074][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-18 13:52:34,043][__main__][INFO] - Logging hyperparameters!
[2024-02-18 13:52:34,048][__main__][INFO] - Starting training!
[2024-02-18 13:52:41,519][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 379, in validation_step
    return self.model.validation_step(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 147, in validation_step
    self.val_acc(preds, targets)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torchmetrics\metric.py", line 290, in forward
    self._forward_cache = self._forward_reduce_state_update(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torchmetrics\metric.py", line 357, in _forward_reduce_state_update
    self.update(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torchmetrics\metric.py", line 456, in wrapped_func
    raise err
  File "D:\Anaconda3\lib\site-packages\torchmetrics\metric.py", line 446, in wrapped_func
    update(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torchmetrics\classification\stat_scores.py", line 314, in update
    _multiclass_stat_scores_tensor_validation(
  File "D:\Anaconda3\lib\site-packages\torchmetrics\functional\classification\stat_scores.py", line 313, in _multiclass_stat_scores_tensor_validation
    raise RuntimeError(
RuntimeError: Detected more unique values in `preds` than `num_classes`. Expected only 10 but found 11 in `preds`.
[2024-02-18 13:52:41,529][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-18_13-51-59
[2024-02-18 13:52:41,530][src.utils.utils][INFO] - Closing wandb!
[2024-02-18 13:53:09,588][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-18 13:53:09,597][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-18 13:53:09,699][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-18 13:53:09,708][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-18 13:53:09,849][__main__][INFO] - Instantiating callbacks...
[2024-02-18 13:53:09,849][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-18 13:53:09,858][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-18 13:53:09,861][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-18 13:53:09,863][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-18 13:53:09,866][__main__][INFO] - Instantiating loggers...
[2024-02-18 13:53:09,866][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-18 13:53:51,017][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-18 13:53:53,260][__main__][INFO] - Logging hyperparameters!
[2024-02-18 13:53:53,267][__main__][INFO] - Starting training!
[2024-02-18 14:00:37,185][__main__][INFO] - Starting testing!
[2024-02-18 14:01:06,894][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-18 14:01:06,903][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-18 14:01:07,014][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-18 14:01:07,020][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-18 14:01:07,169][__main__][INFO] - Instantiating callbacks...
[2024-02-18 14:01:07,169][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-18 14:01:07,175][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-18 14:01:07,178][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-18 14:01:07,180][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-18 14:01:07,183][__main__][INFO] - Instantiating loggers...
[2024-02-18 14:01:07,183][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-18 14:01:38,646][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-18 14:01:39,787][__main__][INFO] - Logging hyperparameters!
[2024-02-18 14:01:39,792][__main__][INFO] - Starting training!
[2024-02-18 14:04:28,506][__main__][INFO] - Starting testing!
[2024-02-18 14:04:54,892][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-18_14-01-06\checkpoints\epoch_002.ckpt
[2024-02-18 14:04:54,897][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-18_14-01-06
[2024-02-18 14:04:54,899][src.utils.utils][INFO] - Closing wandb!
[2024-02-18 14:07:25,660][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-18 14:07:25,668][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-18 14:07:25,755][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-18 14:07:25,761][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-18 14:07:25,872][__main__][INFO] - Instantiating callbacks...
[2024-02-18 14:07:25,873][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-18 14:07:25,880][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-18 14:07:25,883][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-18 14:07:25,887][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-18 14:07:25,892][__main__][INFO] - Instantiating loggers...
[2024-02-18 14:07:25,892][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-18 14:08:08,218][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-18 14:08:10,607][__main__][INFO] - Logging hyperparameters!
[2024-02-18 14:08:10,613][__main__][INFO] - Starting training!
[2024-02-18 14:13:40,347][__main__][INFO] - Starting testing!
[2024-02-18 14:13:52,000][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-18_14-07-25\checkpoints\epoch_002.ckpt
[2024-02-18 14:13:52,003][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-18_14-07-25
[2024-02-18 14:13:52,004][src.utils.utils][INFO] - Closing wandb!
[2024-02-18 14:15:46,588][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-18 14:15:46,596][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-18 14:15:46,694][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-18 14:15:46,701][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-18 14:15:46,816][__main__][INFO] - Instantiating callbacks...
[2024-02-18 14:15:46,817][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-18 14:15:46,821][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-18 14:15:46,824][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-18 14:15:46,825][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-18 14:15:46,829][__main__][INFO] - Instantiating loggers...
[2024-02-18 14:15:46,829][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-18 14:16:42,336][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-18 14:16:45,844][__main__][INFO] - Logging hyperparameters!
[2024-02-18 14:16:45,858][__main__][INFO] - Starting training!
[2024-02-18 14:20:14,497][__main__][INFO] - Starting testing!
[2024-02-21 18:00:09,718][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-21 18:00:09,727][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-21 18:00:09,828][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-21 18:00:09,837][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-21 18:00:10,025][__main__][INFO] - Instantiating callbacks...
[2024-02-21 18:00:10,026][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-21 18:00:10,031][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-21 18:00:10,032][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-21 18:00:10,034][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-21 18:00:10,037][__main__][INFO] - Instantiating loggers...
[2024-02-21 18:00:10,037][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-21 18:00:48,364][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-21 18:00:49,607][__main__][INFO] - Logging hyperparameters!
[2024-02-21 18:00:49,612][__main__][INFO] - Starting training!
[2024-02-21 18:01:00,360][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\Optimizer.py", line 138, in step
    lr = group['lr_base'] + (group['lr_max'] - group['lr_min']) * max(0, 1 - x) * group['gamma'] ** state['step']
KeyError: 'lr_base'
[2024-02-21 18:01:00,369][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-21_18-00-09
[2024-02-21 18:01:00,371][src.utils.utils][INFO] - Closing wandb!
[2024-02-21 18:02:05,725][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-21 18:02:05,738][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-21 18:02:05,863][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-21 18:02:05,870][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-21 18:02:06,012][__main__][INFO] - Instantiating callbacks...
[2024-02-21 18:02:06,012][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-21 18:02:06,018][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-21 18:02:06,020][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-21 18:02:06,022][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-21 18:02:06,028][__main__][INFO] - Instantiating loggers...
[2024-02-21 18:02:06,028][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-21 18:02:30,335][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-21_18-02-05
[2024-02-21 18:02:51,053][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-21 18:02:51,061][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-21 18:02:51,148][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-21 18:02:51,154][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-21 18:02:51,277][__main__][INFO] - Instantiating callbacks...
[2024-02-21 18:02:51,277][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-21 18:02:51,283][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-21 18:02:51,285][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-21 18:02:51,286][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-21 18:02:51,289][__main__][INFO] - Instantiating loggers...
[2024-02-21 18:02:51,289][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-21 18:03:37,718][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-21 18:03:38,801][__main__][INFO] - Logging hyperparameters!
[2024-02-21 18:03:38,810][__main__][INFO] - Starting training!
[2024-02-21 18:05:41,282][__main__][INFO] - Starting testing!
[2024-02-27 16:35:16,305][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-27 16:35:16,314][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-27 16:35:16,396][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-27 16:35:16,404][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-27 16:35:16,559][__main__][INFO] - Instantiating callbacks...
[2024-02-27 16:35:16,559][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-27 16:35:16,566][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-27 16:35:16,567][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-27 16:35:16,568][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-27 16:35:16,570][__main__][INFO] - Instantiating loggers...
[2024-02-27 16:35:16,570][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-27 16:35:46,959][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-27 16:35:48,209][__main__][INFO] - Logging hyperparameters!
[2024-02-27 16:35:48,214][__main__][INFO] - Starting training!
[2024-02-27 16:35:58,536][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 14, in step
    loss = closure()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 367, in training_step
    return self.model.training_step(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 130, in training_step
    optimizer = AWD(self.model.parameters())
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'CIFAR10LitModule' object has no attribute 'model'
[2024-02-27 16:35:58,551][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-27_16-35-16
[2024-02-27 16:35:58,552][src.utils.utils][INFO] - Closing wandb!
[2024-02-27 16:43:47,861][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-27 16:43:47,867][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-27 16:43:47,940][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-27 16:43:47,946][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-27 16:43:48,043][__main__][INFO] - Instantiating callbacks...
[2024-02-27 16:43:48,043][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-27 16:43:48,047][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-27 16:43:48,049][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-27 16:43:48,049][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-27 16:43:48,051][__main__][INFO] - Instantiating loggers...
[2024-02-27 16:43:48,051][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-27 16:44:19,457][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-27 16:44:20,773][__main__][INFO] - Logging hyperparameters!
[2024-02-27 16:44:20,779][__main__][INFO] - Starting training!
[2024-02-27 16:44:29,943][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\ZW.py", line 14, in step
    loss = closure()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 367, in training_step
    return self.model.training_step(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 132, in training_step
    current_lr = self.current_lr
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'CIFAR10LitModule' object has no attribute 'current_lr'
[2024-02-27 16:44:29,970][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-27_16-43-47
[2024-02-27 16:44:29,970][src.utils.utils][INFO] - Closing wandb!
[2024-02-27 17:11:33,601][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-27 17:11:33,608][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-27 17:11:33,693][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-27 17:11:33,701][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-27 17:11:33,823][__main__][INFO] - Instantiating callbacks...
[2024-02-27 17:11:33,823][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-27 17:11:33,828][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-27 17:11:33,829][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-27 17:11:33,830][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-27 17:11:33,833][__main__][INFO] - Instantiating loggers...
[2024-02-27 17:11:33,833][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-27 17:12:06,342][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-27 17:12:07,513][__main__][INFO] - Logging hyperparameters!
[2024-02-27 17:12:07,518][__main__][INFO] - Starting training!
[2024-02-27 17:12:14,085][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\Optimizer.py", line 92, in step
    loss = closure()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 367, in training_step
    return self.model.training_step(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 131, in training_step
    current_lr = self.optimizer.get_current_lr()  # AWD
AttributeError: 'functools.partial' object has no attribute 'get_current_lr'
[2024-02-27 17:12:14,099][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-27_17-11-33
[2024-02-27 17:12:14,099][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 19:26:05,510][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 19:26:05,518][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 19:26:05,597][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 19:26:05,607][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 19:26:05,690][__main__][INFO] - Instantiating callbacks...
[2024-02-28 19:26:05,691][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 19:26:05,695][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 19:26:05,696][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 19:26:05,697][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 19:26:05,700][__main__][INFO] - Instantiating loggers...
[2024-02-28 19:26:05,700][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 19:26:38,069][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 19:26:39,219][__main__][INFO] - Logging hyperparameters!
[2024-02-28 19:26:39,223][__main__][INFO] - Starting training!
[2024-02-28 19:27:57,771][__main__][INFO] - Starting testing!
[2024-02-28 19:31:19,566][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 19:31:19,573][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 19:31:19,661][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 19:31:19,669][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 19:31:19,694][__main__][INFO] - Instantiating callbacks...
[2024-02-28 19:31:19,694][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 19:31:19,700][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 19:31:19,702][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 19:31:19,703][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 19:31:19,706][__main__][INFO] - Instantiating loggers...
[2024-02-28 19:31:19,706][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 19:31:54,169][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 19:31:55,296][__main__][INFO] - Logging hyperparameters!
[2024-02-28 19:31:55,299][__main__][INFO] - Starting training!
[2024-02-28 19:32:02,325][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
TypeError: step() got an unexpected keyword argument 'closure'
[2024-02-28 19:32:02,336][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_19-31-19
[2024-02-28 19:32:02,337][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 20:25:09,375][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 20:25:09,384][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 20:25:09,482][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 20:25:09,493][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 20:25:09,521][__main__][INFO] - Instantiating callbacks...
[2024-02-28 20:25:09,522][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 20:25:09,526][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 20:25:09,528][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 20:25:09,528][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 20:25:09,532][__main__][INFO] - Instantiating loggers...
[2024-02-28 20:25:09,532][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 20:25:16,218][wandb.sdk.lib.retry][INFO] - Retry attempt failed:
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "D:\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Anaconda3\lib\socket.py", line 954, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "D:\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "D:\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "D:\Anaconda3\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "D:\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x00000191F07E6400>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "D:\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "D:\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000191F07E6400>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\lib\retry.py", line 131, in __call__
    result = self._call_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\internal\internal_api.py", line 322, in execute
    return self.client.execute(*args, **kwargs)  # type: ignore
  File "D:\Anaconda3\lib\site-packages\wandb\vendor\gql-0.2.0\wandb_gql\client.py", line 52, in execute
    result = self._get_result(document, *args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\wandb\vendor\gql-0.2.0\wandb_gql\client.py", line 60, in _get_result
    return self.transport.execute(document, *args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\lib\gql_request.py", line 55, in execute
    request = self.session.post(self.url, **post_args)
  File "D:\Anaconda3\lib\site-packages\requests\sessions.py", line 635, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "D:\Anaconda3\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Anaconda3\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "D:\Anaconda3\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000191F07E6400>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
[2024-02-28 20:25:57,449][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 20:25:58,793][__main__][INFO] - Logging hyperparameters!
[2024-02-28 20:25:58,796][__main__][INFO] - Starting training!
[2024-02-28 20:26:06,399][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
TypeError: step() got an unexpected keyword argument 'closure'
[2024-02-28 20:26:06,407][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_20-25-09
[2024-02-28 20:26:06,408][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 20:29:28,657][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 20:29:28,664][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 20:29:28,753][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 20:29:28,761][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 20:29:28,785][__main__][INFO] - Instantiating callbacks...
[2024-02-28 20:29:28,786][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 20:29:28,790][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 20:29:28,793][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 20:29:28,793][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 20:29:28,797][__main__][INFO] - Instantiating loggers...
[2024-02-28 20:29:28,798][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 20:38:10,939][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 20:38:10,946][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 20:38:11,032][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 20:38:11,038][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 20:38:11,059][__main__][INFO] - Instantiating callbacks...
[2024-02-28 20:38:11,060][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 20:38:11,064][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 20:38:11,066][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 20:38:11,066][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 20:38:11,069][__main__][INFO] - Instantiating loggers...
[2024-02-28 20:38:11,070][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 20:38:43,966][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 20:38:45,012][__main__][INFO] - Logging hyperparameters!
[2024-02-28 20:38:45,015][__main__][INFO] - Starting training!
[2024-02-28 20:40:13,502][__main__][INFO] - Starting testing!
[2024-02-28 20:43:34,340][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 20:43:34,352][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 20:43:34,497][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 20:43:34,510][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 20:43:34,550][__main__][INFO] - Instantiating callbacks...
[2024-02-28 20:43:34,551][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 20:43:34,560][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 20:43:34,562][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 20:43:34,564][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 20:43:34,568][__main__][INFO] - Instantiating loggers...
[2024-02-28 20:43:34,570][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 20:44:14,658][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 20:44:15,904][__main__][INFO] - Logging hyperparameters!
[2024-02-28 20:44:15,910][__main__][INFO] - Starting training!
[2024-02-28 20:46:27,748][__main__][INFO] - Starting testing!
[2024-02-28 20:46:33,416][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_20-43-34\checkpoints\epoch_000.ckpt
[2024-02-28 20:46:33,417][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_20-43-34
[2024-02-28 20:46:33,418][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 20:46:47,556][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-28 21:04:42,443][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 21:04:42,450][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 21:04:42,533][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 21:04:42,540][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 21:04:42,560][__main__][INFO] - Instantiating callbacks...
[2024-02-28 21:04:42,561][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 21:04:42,564][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 21:04:42,567][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 21:04:42,567][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 21:04:42,570][__main__][INFO] - Instantiating loggers...
[2024-02-28 21:04:42,570][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 21:05:14,281][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 21:05:15,374][__main__][INFO] - Logging hyperparameters!
[2024-02-28 21:05:15,378][__main__][INFO] - Starting training!
[2024-02-28 21:07:26,070][__main__][INFO] - Starting testing!
[2024-02-28 21:07:32,850][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-04-42\checkpoints\epoch_003.ckpt
[2024-02-28 21:07:32,852][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-04-42
[2024-02-28 21:07:32,852][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 21:08:08,898][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-28 21:10:04,501][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 21:10:04,510][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 21:10:04,595][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 21:10:04,606][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 21:10:04,632][__main__][INFO] - Instantiating callbacks...
[2024-02-28 21:10:04,632][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 21:10:04,636][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 21:10:04,637][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 21:10:04,638][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 21:10:04,640][__main__][INFO] - Instantiating loggers...
[2024-02-28 21:10:04,641][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 21:10:36,246][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 21:10:37,335][__main__][INFO] - Logging hyperparameters!
[2024-02-28 21:10:37,338][__main__][INFO] - Starting training!
[2024-02-28 21:12:47,675][__main__][INFO] - Starting testing!
[2024-02-28 21:12:53,058][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-10-04\checkpoints\epoch_004.ckpt
[2024-02-28 21:12:53,060][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-10-04
[2024-02-28 21:12:53,060][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 21:13:03,440][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-28 21:15:55,345][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 21:15:55,352][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 21:15:55,452][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 21:15:55,457][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 21:15:55,479][__main__][INFO] - Instantiating callbacks...
[2024-02-28 21:15:55,479][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 21:15:55,485][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 21:15:55,487][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 21:15:55,488][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 21:15:55,490][__main__][INFO] - Instantiating loggers...
[2024-02-28 21:15:55,490][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 21:16:27,819][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 21:16:28,824][__main__][INFO] - Logging hyperparameters!
[2024-02-28 21:16:28,826][__main__][INFO] - Starting training!
[2024-02-28 21:17:16,246][__main__][INFO] - Starting testing!
[2024-02-28 21:19:02,603][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 21:19:02,614][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 21:19:02,747][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 21:19:02,759][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 21:19:02,794][__main__][INFO] - Instantiating callbacks...
[2024-02-28 21:19:02,794][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 21:19:02,799][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 21:19:02,800][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 21:19:02,801][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 21:19:02,803][__main__][INFO] - Instantiating loggers...
[2024-02-28 21:19:02,804][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 21:19:38,915][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 21:19:40,051][__main__][INFO] - Logging hyperparameters!
[2024-02-28 21:19:40,054][__main__][INFO] - Starting training!
[2024-02-28 21:19:46,406][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\Adam.py", line 115, in step
    p.data.addcdiv_(-step_size, grad, denom)
TypeError: addcdiv_() takes 2 positional arguments but 3 were given
[2024-02-28 21:19:46,413][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-19-02
[2024-02-28 21:19:46,414][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 21:24:37,001][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 21:24:37,010][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 21:24:37,127][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 21:24:37,135][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 21:24:37,170][__main__][INFO] - Instantiating callbacks...
[2024-02-28 21:24:37,170][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 21:24:37,175][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 21:24:37,177][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 21:24:37,178][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 21:24:37,182][__main__][INFO] - Instantiating loggers...
[2024-02-28 21:24:37,183][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 21:25:14,753][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 21:25:15,840][__main__][INFO] - Logging hyperparameters!
[2024-02-28 21:25:15,843][__main__][INFO] - Starting training!
[2024-02-28 21:27:30,111][__main__][INFO] - Starting testing!
[2024-02-28 21:27:35,753][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-24-36\checkpoints\epoch_004.ckpt
[2024-02-28 21:27:35,754][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-24-36
[2024-02-28 21:27:35,755][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 21:27:49,228][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-28 21:28:05,764][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 21:28:05,772][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 21:28:05,854][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 21:28:05,860][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 21:28:05,881][__main__][INFO] - Instantiating callbacks...
[2024-02-28 21:28:05,882][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 21:28:05,887][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 21:28:05,888][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 21:28:05,889][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 21:28:05,892][__main__][INFO] - Instantiating loggers...
[2024-02-28 21:28:05,892][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 21:28:36,827][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 21:28:37,763][__main__][INFO] - Logging hyperparameters!
[2024-02-28 21:28:37,766][__main__][INFO] - Starting training!
[2024-02-28 21:30:47,522][__main__][INFO] - Starting testing!
[2024-02-28 21:30:54,068][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-28-05\checkpoints\epoch_004.ckpt
[2024-02-28 21:30:54,071][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-28-05
[2024-02-28 21:30:54,072][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 21:31:04,281][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-02-28 21:32:30,757][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-02-28 21:32:30,765][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-02-28 21:32:30,860][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-02-28 21:32:30,866][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-02-28 21:32:30,889][__main__][INFO] - Instantiating callbacks...
[2024-02-28 21:32:30,890][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-02-28 21:32:30,894][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-02-28 21:32:30,896][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-02-28 21:32:30,896][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-02-28 21:32:30,899][__main__][INFO] - Instantiating loggers...
[2024-02-28 21:32:30,899][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-02-28 21:33:02,891][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-02-28 21:33:03,779][__main__][INFO] - Logging hyperparameters!
[2024-02-28 21:33:03,782][__main__][INFO] - Starting training!
[2024-02-28 21:35:13,530][__main__][INFO] - Starting testing!
[2024-02-28 21:35:20,784][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-32-30\checkpoints\epoch_004.ckpt
[2024-02-28 21:35:20,785][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-02-28_21-32-30
[2024-02-28 21:35:20,786][src.utils.utils][INFO] - Closing wandb!
[2024-02-28 21:35:32,600][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-03-01 20:08:45,795][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 20:08:45,817][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 20:08:45,939][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 20:08:45,951][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 20:08:46,039][__main__][INFO] - Instantiating callbacks...
[2024-03-01 20:08:46,040][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-01 20:08:46,048][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-01 20:08:46,050][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-01 20:08:46,051][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-01 20:08:46,055][__main__][INFO] - Instantiating loggers...
[2024-03-01 20:08:46,055][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-01 20:09:18,309][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-01 20:09:19,641][__main__][INFO] - Logging hyperparameters!
[2024-03-01 20:09:19,646][__main__][INFO] - Starting training!
[2024-03-01 20:09:52,265][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 20:09:52,273][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 20:09:52,345][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 20:09:52,351][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 20:09:52,526][__main__][INFO] - Instantiating callbacks...
[2024-03-01 20:09:52,527][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-01 20:09:52,535][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-01 20:09:52,538][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-01 20:09:52,539][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-01 20:09:52,542][__main__][INFO] - Instantiating loggers...
[2024-03-01 20:09:52,543][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-01 20:10:22,339][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-01 20:10:23,634][__main__][INFO] - Logging hyperparameters!
[2024-03-01 20:10:23,640][__main__][INFO] - Starting training!
[2024-03-01 20:29:22,332][__main__][INFO] - Starting testing!
[2024-03-01 20:29:29,734][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-01_20-09-52\checkpoints\epoch_007.ckpt
[2024-03-01 20:29:29,736][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-01_20-09-52
[2024-03-01 20:29:29,736][src.utils.utils][INFO] - Closing wandb!
[2024-03-01 20:29:41,905][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-03-01 20:29:56,807][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 20:29:56,815][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 20:29:56,948][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 20:29:56,968][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 20:29:57,221][__main__][INFO] - Instantiating callbacks...
[2024-03-01 20:29:57,223][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-01 20:29:57,229][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-01 20:29:57,231][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-01 20:29:57,232][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-01 20:29:57,235][__main__][INFO] - Instantiating loggers...
[2024-03-01 20:29:57,235][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-01 20:30:30,513][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-01 20:30:31,746][__main__][INFO] - Logging hyperparameters!
[2024-03-01 20:30:31,750][__main__][INFO] - Starting training!
[2024-03-01 20:46:27,475][__main__][INFO] - Starting testing!
[2024-03-01 20:50:44,114][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 20:50:44,122][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 20:50:44,215][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 20:50:44,220][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 20:50:44,235][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
TypeError: __init__() missing 2 required positional arguments: 'ch_in' and 'ch_out'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 53, in train
    model: LightningModule = hydra.utils.instantiate(cfg.model)
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 342, in instantiate_node
    value = instantiate_node(
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'srcC.models.components.resnet.ResBlk':
TypeError("__init__() missing 2 required positional arguments: 'ch_in' and 'ch_out'")
full_key: model.net
[2024-03-01 20:50:44,239][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-01_20-50-44
[2024-03-01 20:51:16,523][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 20:51:16,528][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 20:51:16,605][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 20:51:16,611][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 20:51:16,618][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
TypeError: __init__() missing 1 required positional argument: 'num_class'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 53, in train
    model: LightningModule = hydra.utils.instantiate(cfg.model)
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 342, in instantiate_node
    value = instantiate_node(
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'srcC.models.components.resnet.ResNet18':
TypeError("__init__() missing 1 required positional argument: 'num_class'")
full_key: model.net
[2024-03-01 20:51:16,620][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-01_20-51-16
[2024-03-01 20:52:05,724][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 20:52:05,731][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 20:52:05,804][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 20:52:05,811][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 20:52:05,854][__main__][INFO] - Instantiating callbacks...
[2024-03-01 20:52:05,855][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-01 20:52:05,860][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-01 20:52:05,863][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-01 20:52:05,864][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-01 20:52:05,866][__main__][INFO] - Instantiating loggers...
[2024-03-01 20:52:05,867][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-01 20:52:39,254][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-01 20:52:40,317][__main__][INFO] - Logging hyperparameters!
[2024-03-01 20:52:40,320][__main__][INFO] - Starting training!
[2024-03-01 20:52:47,191][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 379, in validation_step
    return self.model.validation_step(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 144, in validation_step
    loss, preds, targets = self.model_step(batch)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 108, in model_step
    logits = self.forward(x)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 85, in forward
    return self.net(x)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\components\resnet.py", line 86, in forward
    x = self.outlayer(x)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x256 and 2304x10)
[2024-03-01 20:52:47,201][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-01_20-52-05
[2024-03-01 20:52:47,201][src.utils.utils][INFO] - Closing wandb!
[2024-03-01 20:54:53,740][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 20:54:53,751][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 20:54:53,841][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 20:54:53,848][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 20:54:53,886][__main__][INFO] - Instantiating callbacks...
[2024-03-01 20:54:53,887][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-01 20:54:53,891][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-01 20:54:53,893][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-01 20:54:53,894][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-01 20:54:53,897][__main__][INFO] - Instantiating loggers...
[2024-03-01 20:54:53,897][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-01 20:55:29,967][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-01 20:55:30,924][__main__][INFO] - Logging hyperparameters!
[2024-03-01 20:55:30,927][__main__][INFO] - Starting training!
[2024-03-01 20:55:37,562][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 379, in validation_step
    return self.model.validation_step(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 144, in validation_step
    loss, preds, targets = self.model_step(batch)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 108, in model_step
    logits = self.forward(x)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 85, in forward
    return self.net(x)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\components\resnet.py", line 86, in forward
    x = self.outlayer(x)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x256 and 2304x10)
[2024-03-01 20:55:37,569][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-01_20-54-53
[2024-03-01 20:55:37,569][src.utils.utils][INFO] - Closing wandb!
[2024-03-01 20:58:54,014][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 20:58:54,022][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 20:58:54,096][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 20:58:54,101][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 20:58:54,137][__main__][INFO] - Instantiating callbacks...
[2024-03-01 20:58:54,137][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-01 20:58:54,141][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-01 20:58:54,144][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-01 20:58:54,144][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-01 20:58:54,147][__main__][INFO] - Instantiating loggers...
[2024-03-01 20:58:54,147][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-01 20:59:26,922][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-01 20:59:28,106][__main__][INFO] - Logging hyperparameters!
[2024-03-01 20:59:28,110][__main__][INFO] - Starting training!
[2024-03-01 21:07:38,418][__main__][INFO] - Starting testing!
[2024-03-01 21:08:10,471][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 21:08:10,480][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 21:08:10,567][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 21:08:10,574][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 21:08:10,618][__main__][INFO] - Instantiating callbacks...
[2024-03-01 21:08:10,618][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-01 21:08:10,622][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-01 21:08:10,624][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-01 21:08:10,624][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-01 21:08:10,626][__main__][INFO] - Instantiating loggers...
[2024-03-01 21:08:10,627][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-01 21:08:45,061][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-01 21:08:46,759][__main__][INFO] - Logging hyperparameters!
[2024-03-01 21:08:46,764][__main__][INFO] - Starting training!
[2024-03-01 21:13:25,867][__main__][INFO] - Starting testing!
[2024-03-01 21:13:51,276][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-01 21:13:51,283][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-01 21:13:51,376][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-01 21:13:51,382][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-01 21:13:51,419][__main__][INFO] - Instantiating callbacks...
[2024-03-01 21:13:51,419][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-01 21:13:51,423][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-01 21:13:51,425][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-01 21:13:51,426][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-01 21:13:51,428][__main__][INFO] - Instantiating loggers...
[2024-03-01 21:13:51,428][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-01 21:14:27,919][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-01 21:14:29,248][__main__][INFO] - Logging hyperparameters!
[2024-03-01 21:14:29,252][__main__][INFO] - Starting training!
[2024-03-01 21:17:27,351][__main__][INFO] - Starting testing!
[2024-03-02 13:44:50,250][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-02 13:44:50,257][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-02 13:44:50,333][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-02 13:44:50,340][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-02 13:44:50,479][__main__][INFO] - Instantiating callbacks...
[2024-03-02 13:44:50,479][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-02 13:44:50,487][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-02 13:44:50,489][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-02 13:44:50,491][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-02 13:44:50,494][__main__][INFO] - Instantiating loggers...
[2024-03-02 13:44:50,494][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-02 13:45:20,675][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-02 13:45:22,073][__main__][INFO] - Logging hyperparameters!
[2024-03-02 13:45:22,078][__main__][INFO] - Starting training!
[2024-03-02 13:57:19,892][__main__][INFO] - Starting testing!
[2024-03-04 19:39:34,654][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-04 19:39:34,662][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-04 19:39:34,742][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-04 19:39:34,751][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-04 19:39:34,899][__main__][INFO] - Instantiating callbacks...
[2024-03-04 19:39:34,900][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-04 19:39:34,905][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-04 19:39:34,907][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-04 19:39:34,908][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-04 19:39:34,913][__main__][INFO] - Instantiating loggers...
[2024-03-04 19:39:34,920][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-04 19:40:06,733][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-04 19:40:07,847][__main__][INFO] - Logging hyperparameters!
[2024-03-04 19:40:07,852][__main__][INFO] - Starting training!
[2024-03-04 19:40:14,687][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 189, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'weight_decay'
[2024-03-04 19:40:14,696][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-04_19-39-34
[2024-03-04 19:40:14,697][src.utils.utils][INFO] - Closing wandb!
[2024-03-04 19:43:31,812][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-04 19:43:31,820][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-04 19:43:31,908][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-04 19:43:31,916][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-04 19:43:32,026][__main__][INFO] - Instantiating callbacks...
[2024-03-04 19:43:32,026][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-04 19:43:32,032][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-04 19:43:32,034][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-04 19:43:32,035][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-04 19:43:32,038][__main__][INFO] - Instantiating loggers...
[2024-03-04 19:43:32,038][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-04 19:44:06,479][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-04 19:44:07,423][__main__][INFO] - Logging hyperparameters!
[2024-03-04 19:44:07,428][__main__][INFO] - Starting training!
[2024-03-04 19:44:16,201][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\optim\Adam.py", line 111, in step
    step_size = group['lr'] * torch.sqrt(bias_correction2) / bias_correction1
TypeError: sqrt(): argument 'input' (position 1) must be Tensor, not float
[2024-03-04 19:44:16,210][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-04_19-43-31
[2024-03-04 19:44:16,210][src.utils.utils][INFO] - Closing wandb!
[2024-03-04 19:51:46,838][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-04 19:51:46,845][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-04 19:51:46,935][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-04 19:51:46,940][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-04 19:51:47,043][__main__][INFO] - Instantiating callbacks...
[2024-03-04 19:51:47,044][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-04 19:51:47,050][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-04 19:51:47,053][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-04 19:51:47,054][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-04 19:51:47,056][__main__][INFO] - Instantiating loggers...
[2024-03-04 19:51:47,056][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-04 19:52:22,593][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-04 19:52:23,684][__main__][INFO] - Logging hyperparameters!
[2024-03-04 19:52:23,689][__main__][INFO] - Starting training!
[2024-03-04 19:52:29,547][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\single_device.py", line 75, in setup
    super().setup(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 149, in setup
    self.setup_optimizers(trainer)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 168, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 189, in configure_optimizers
    optimizer = self.hparams.optimizer(params=self.parameters())
TypeError: __init__() got an unexpected keyword argument 'weight_decay'
[2024-03-04 19:52:29,557][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-04_19-51-46
[2024-03-04 19:52:29,558][src.utils.utils][INFO] - Closing wandb!
[2024-03-04 19:53:40,056][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-04 19:53:40,063][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-04 19:53:40,156][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-04 19:53:40,163][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-04 19:53:40,288][__main__][INFO] - Instantiating callbacks...
[2024-03-04 19:53:40,288][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-04 19:53:40,292][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-04 19:53:40,294][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-04 19:53:40,294][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-04 19:53:40,297][__main__][INFO] - Instantiating loggers...
[2024-03-04 19:53:40,297][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-04 19:54:12,094][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-04 19:54:13,338][__main__][INFO] - Logging hyperparameters!
[2024-03-04 19:54:13,343][__main__][INFO] - Starting training!
[2024-03-04 19:58:53,376][__main__][INFO] - Starting testing!
[2024-03-04 19:59:00,493][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-04_19-53-39\checkpoints\epoch_002.ckpt
[2024-03-04 19:59:00,495][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-04_19-53-39
[2024-03-04 19:59:00,495][src.utils.utils][INFO] - Closing wandb!
[2024-03-04 20:09:42,926][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-03-04 20:09:57,364][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-04 20:09:57,372][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-04 20:09:57,470][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-04 20:09:57,477][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-04 20:09:57,594][__main__][INFO] - Instantiating callbacks...
[2024-03-04 20:09:57,594][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-04 20:09:57,599][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-04 20:09:57,601][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-04 20:09:57,603][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-04 20:09:57,608][__main__][INFO] - Instantiating loggers...
[2024-03-04 20:09:57,608][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-04 20:10:29,609][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-04 20:10:30,761][__main__][INFO] - Logging hyperparameters!
[2024-03-04 20:10:30,770][__main__][INFO] - Starting training!
[2024-03-04 20:10:58,161][__main__][INFO] - Starting testing!
[2024-03-04 20:10:58,163][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2024-03-04 21:05:34,701][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-04 21:05:34,708][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-04 21:05:34,784][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-04 21:05:34,790][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-04 21:05:34,887][__main__][INFO] - Instantiating callbacks...
[2024-03-04 21:05:34,888][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-04 21:05:34,892][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-04 21:05:34,893][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-04 21:05:34,894][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-04 21:05:34,896][__main__][INFO] - Instantiating loggers...
[2024-03-04 21:05:34,896][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-04 21:06:10,612][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-04 21:06:11,611][__main__][INFO] - Logging hyperparameters!
[2024-03-04 21:06:11,615][__main__][INFO] - Starting training!
[2024-03-04 21:08:06,748][__main__][INFO] - Starting testing!
[2024-03-08 17:19:01,850][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-08 17:19:01,859][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-08 17:19:01,945][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-08 17:19:01,952][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-08 17:19:02,107][__main__][INFO] - Instantiating callbacks...
[2024-03-08 17:19:02,108][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-08 17:19:02,114][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-08 17:19:02,117][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-08 17:19:02,118][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-08 17:19:02,121][__main__][INFO] - Instantiating loggers...
[2024-03-08 17:19:02,122][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-08 17:19:04,037][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_init.py", line 1143, in init
    wi.setup(kwargs)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_init.py", line 172, in setup
    self._wl = wandb_setup.setup(settings=setup_settings)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_setup.py", line 327, in setup
    ret = _setup(settings=settings)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_setup.py", line 320, in _setup
    wl = _WandbSetup(settings=settings)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_setup.py", line 303, in __init__
    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_setup.py", line 114, in __init__
    self._setup()
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_setup.py", line 250, in _setup
    self._setup_manager()
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_setup.py", line 277, in _setup_manager
    self._manager = wandb_manager._Manager(settings=self._settings)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_manager.py", line 144, in __init__
    self._service.start()
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\service\service.py", line 218, in start
    self._launch_server()
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\service\service.py", line 210, in _launch_server
    self._wait_for_ports(fname, proc=internal_proc)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\service\service.py", line 125, in _wait_for_ports
    time.sleep(0.2)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loggers\wandb.py", line 358, in __init__
    _ = self.experiment
  File "D:\Anaconda3\lib\site-packages\lightning\fabric\loggers\logger.py", line 114, in experiment
    return fn(self)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loggers\wandb.py", line 406, in experiment
    self._experiment = wandb.init(**self._wandb_init)
  File "D:\Anaconda3\lib\site-packages\wandb\sdk\wandb_init.py", line 1168, in init
    assert logger
AssertionError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 59, in train
    logger: List[Logger] = utils.instantiate_loggers(cfg.get("logger"))
  File "D:\pycharmproject\template\src\utils\instantiators.py", line 48, in instantiate_loggers
    logger.append(hydra.utils.instantiate(lg_conf))
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "D:\Anaconda3\lib\site-packages\hydra\_internal\instantiate\_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'lightning.pytorch.loggers.wandb.WandbLogger':
AssertionError()
full_key: logger.wandb
[2024-03-08 17:19:04,048][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-08_17-19-01
[2024-03-08 17:19:25,735][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-08 17:19:25,743][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-08 17:19:25,835][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-08 17:19:25,841][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-08 17:19:26,077][__main__][INFO] - Instantiating callbacks...
[2024-03-08 17:19:26,078][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-08 17:19:26,091][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-08 17:19:26,094][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-08 17:19:26,095][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-08 17:19:26,102][__main__][INFO] - Instantiating loggers...
[2024-03-08 17:19:26,105][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-08 17:20:04,605][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-08 17:20:05,649][__main__][INFO] - Logging hyperparameters!
[2024-03-08 17:20:05,653][__main__][INFO] - Starting training!
[2024-03-08 17:22:17,248][__main__][INFO] - Starting testing!
[2024-03-09 15:01:26,228][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-09 15:01:26,240][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-09 15:01:26,377][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-09 15:01:26,391][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-09 15:01:27,176][__main__][INFO] - Instantiating callbacks...
[2024-03-09 15:01:27,176][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-09 15:01:27,182][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-09 15:01:27,184][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-09 15:01:27,185][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-09 15:01:27,187][__main__][INFO] - Instantiating loggers...
[2024-03-09 15:01:27,189][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-09 15:02:06,063][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-09 15:02:07,769][__main__][INFO] - Logging hyperparameters!
[2024-03-09 15:02:07,776][__main__][INFO] - Starting training!
[2024-03-09 15:07:36,479][__main__][INFO] - Starting testing!
[2024-03-09 15:07:53,515][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-09_15-01-26\checkpoints\epoch_000.ckpt
[2024-03-09 15:07:53,516][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-09_15-01-26
[2024-03-09 15:07:53,517][src.utils.utils][INFO] - Closing wandb!
[2024-03-11 17:21:27,475][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-11 17:21:27,483][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-11 17:21:27,573][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-11 17:21:27,580][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-11 17:21:27,680][__main__][INFO] - Instantiating callbacks...
[2024-03-11 17:21:27,681][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-11 17:21:27,684][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-11 17:21:27,685][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-11 17:21:27,686][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-11 17:21:27,688][__main__][INFO] - Instantiating loggers...
[2024-03-11 17:21:27,688][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-11 17:21:55,363][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-11 17:21:56,624][__main__][INFO] - Logging hyperparameters!
[2024-03-11 17:21:56,628][__main__][INFO] - Starting training!
[2024-03-11 17:23:12,198][__main__][INFO] - Starting testing!
[2024-03-11 17:23:18,495][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_17-21-27\checkpoints\epoch_000.ckpt
[2024-03-11 17:23:18,496][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_17-21-27
[2024-03-11 17:23:18,497][src.utils.utils][INFO] - Closing wandb!
[2024-03-11 17:23:48,919][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-03-11 17:32:30,242][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-11 17:32:30,248][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-11 17:32:30,322][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-11 17:32:30,327][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-11 17:32:30,398][__main__][INFO] - Instantiating callbacks...
[2024-03-11 17:32:30,399][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-11 17:32:30,402][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-11 17:32:30,404][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-11 17:32:30,404][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-11 17:32:30,406][__main__][INFO] - Instantiating loggers...
[2024-03-11 17:32:30,406][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-11 17:33:00,424][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-11 17:33:01,619][__main__][INFO] - Logging hyperparameters!
[2024-03-11 17:33:01,623][__main__][INFO] - Starting training!
[2024-03-11 17:34:07,472][__main__][INFO] - Starting testing!
[2024-03-11 17:34:14,339][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_17-32-30\checkpoints\epoch_000.ckpt
[2024-03-11 17:34:14,341][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_17-32-30
[2024-03-11 17:34:14,341][src.utils.utils][INFO] - Closing wandb!
[2024-03-11 17:34:29,964][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-03-11 17:38:11,480][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-11 17:38:11,487][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-11 17:38:11,561][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-11 17:38:11,567][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-11 17:38:11,766][__main__][INFO] - Instantiating callbacks...
[2024-03-11 17:38:11,767][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-11 17:38:11,771][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-11 17:38:11,773][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-11 17:38:11,773][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-11 17:38:11,776][__main__][INFO] - Instantiating loggers...
[2024-03-11 17:38:11,777][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-11 17:38:41,896][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-11 17:38:43,038][__main__][INFO] - Logging hyperparameters!
[2024-03-11 17:38:43,042][__main__][INFO] - Starting training!
[2024-03-11 17:41:09,378][__main__][INFO] - Starting testing!
[2024-03-11 17:41:17,868][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_17-38-11\checkpoints\epoch_001.ckpt
[2024-03-11 17:41:17,870][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_17-38-11
[2024-03-11 17:41:17,871][src.utils.utils][INFO] - Closing wandb!
[2024-03-11 17:41:32,795][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-03-11 19:33:52,842][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-11 19:33:52,850][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-11 19:33:52,921][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-11 19:33:52,927][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-11 19:33:53,124][__main__][INFO] - Instantiating callbacks...
[2024-03-11 19:33:53,125][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-11 19:33:53,128][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-11 19:33:53,130][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-11 19:33:53,132][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-11 19:33:53,135][__main__][INFO] - Instantiating loggers...
[2024-03-11 19:33:53,136][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-11 19:34:29,096][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-11 19:34:30,373][__main__][INFO] - Logging hyperparameters!
[2024-03-11 19:34:30,378][__main__][INFO] - Starting training!
[2024-03-11 19:37:18,812][__main__][INFO] - Starting testing!
[2024-03-11 19:37:37,653][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_19-33-52\checkpoints\epoch_001.ckpt
[2024-03-11 19:37:37,657][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_19-33-52
[2024-03-11 19:37:37,659][src.utils.utils][INFO] - Closing wandb!
[2024-03-11 19:37:53,402][src.utils.utils][INFO] - Metric name is None! Skipping metric value retrieval...
[2024-03-11 19:45:31,686][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-11 19:45:31,695][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-11 19:45:31,790][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-11 19:45:31,798][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-11 19:45:32,009][__main__][INFO] - Instantiating callbacks...
[2024-03-11 19:45:32,009][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-11 19:45:32,015][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-11 19:45:32,017][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-11 19:45:32,018][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-11 19:45:32,021][__main__][INFO] - Instantiating loggers...
[2024-03-11 19:45:32,022][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-11 19:46:09,960][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-11 19:46:11,464][__main__][INFO] - Logging hyperparameters!
[2024-03-11 19:46:11,469][__main__][INFO] - Starting training!
[2024-03-11 19:48:59,901][__main__][INFO] - Starting testing!
[2024-03-11 19:49:08,610][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_19-45-31\checkpoints\epoch_001.ckpt
[2024-03-11 19:49:08,612][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-11_19-45-31
[2024-03-11 19:49:08,612][src.utils.utils][INFO] - Closing wandb!
[2024-03-12 19:14:19,645][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-12 19:14:19,653][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-12 19:14:19,738][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-12 19:14:19,747][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-12 19:14:19,965][__main__][INFO] - Instantiating callbacks...
[2024-03-12 19:14:19,966][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-12 19:14:19,971][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-12 19:14:19,973][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-12 19:14:19,974][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-12 19:14:19,977][__main__][INFO] - Instantiating loggers...
[2024-03-12 19:14:19,977][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-12 19:14:56,393][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-12 19:14:57,739][__main__][INFO] - Logging hyperparameters!
[2024-03-12 19:14:57,745][__main__][INFO] - Starting training!
[2024-03-12 19:16:45,817][__main__][INFO] - Starting testing!
[2024-03-12 19:17:53,183][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-12 19:17:53,191][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-12 19:17:53,259][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-12 19:17:53,265][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-12 19:17:53,446][__main__][INFO] - Instantiating callbacks...
[2024-03-12 19:17:53,447][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-12 19:17:53,453][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-12 19:17:53,455][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-12 19:17:53,456][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-12 19:17:53,459][__main__][INFO] - Instantiating loggers...
[2024-03-12 19:17:53,459][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-12 19:18:21,486][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-12 19:18:22,523][__main__][INFO] - Logging hyperparameters!
[2024-03-12 19:18:22,532][__main__][INFO] - Starting training!
[2024-03-12 19:18:30,296][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "D:\pycharmproject\template\src\utils\utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "D:\pycharmproject\template\srcC\train.py", line 83, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 973, in _run
    results = self._run_stage()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 201, in run
    self.advance()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\core\optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torch\optim\adam.py", line 121, in step
    loss = closure()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\plugins\precision\precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\loops\optimization\automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\trainer\call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\lightning\pytorch\strategies\strategy.py", line 367, in training_step
    return self.model.training_step(*args, **kwargs)
  File "D:\pycharmproject\template\srcC\models\CIFAR10_module.py", line 127, in training_step
    self.train_acc(preds, targets)
  File "D:\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torchmetrics\metric.py", line 290, in forward
    self._forward_cache = self._forward_reduce_state_update(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torchmetrics\metric.py", line 357, in _forward_reduce_state_update
    self.update(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torchmetrics\metric.py", line 456, in wrapped_func
    raise err
  File "D:\Anaconda3\lib\site-packages\torchmetrics\metric.py", line 446, in wrapped_func
    update(*args, **kwargs)
  File "D:\Anaconda3\lib\site-packages\torchmetrics\classification\stat_scores.py", line 314, in update
    _multiclass_stat_scores_tensor_validation(
  File "D:\Anaconda3\lib\site-packages\torchmetrics\functional\classification\stat_scores.py", line 313, in _multiclass_stat_scores_tensor_validation
    raise RuntimeError(
RuntimeError: Detected more unique values in `preds` than `num_classes`. Expected only 10 but found 56 in `preds`.
[2024-03-12 19:18:30,328][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-12_19-17-53
[2024-03-12 19:18:30,330][src.utils.utils][INFO] - Closing wandb!
[2024-03-12 19:20:36,684][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-12 19:20:36,691][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-12 19:20:36,787][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-12 19:20:36,794][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-12 19:20:36,972][__main__][INFO] - Instantiating callbacks...
[2024-03-12 19:20:36,973][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-12 19:20:36,976][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-12 19:20:36,979][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-12 19:20:36,980][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-12 19:20:36,982][__main__][INFO] - Instantiating loggers...
[2024-03-12 19:20:36,982][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-12 19:21:04,578][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-12 19:21:05,688][__main__][INFO] - Logging hyperparameters!
[2024-03-12 19:21:05,695][__main__][INFO] - Starting training!
[2024-03-12 19:25:19,341][__main__][INFO] - Starting testing!
[2024-03-12 19:25:34,076][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-12_19-20-36\checkpoints\epoch_001.ckpt
[2024-03-12 19:25:34,078][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-12_19-20-36
[2024-03-12 19:25:34,078][src.utils.utils][INFO] - Closing wandb!
[2024-03-12 20:21:59,417][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2024-03-12 20:21:59,427][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2024-03-12 20:21:59,536][__main__][INFO] - Instantiating datamodule <srcC.data.CIFAR10_datamodule.CIFAR10DataModule>
[2024-03-12 20:21:59,544][__main__][INFO] - Instantiating model <srcC.models.CIFAR10_module.CIFAR10LitModule>
[2024-03-12 20:21:59,603][__main__][INFO] - Instantiating callbacks...
[2024-03-12 20:21:59,604][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2024-03-12 20:21:59,611][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2024-03-12 20:21:59,613][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2024-03-12 20:21:59,615][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2024-03-12 20:21:59,618][__main__][INFO] - Instantiating loggers...
[2024-03-12 20:21:59,620][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>
[2024-03-12 20:22:31,136][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2024-03-12 20:22:32,516][__main__][INFO] - Logging hyperparameters!
[2024-03-12 20:22:32,520][__main__][INFO] - Starting training!
[2024-03-12 20:23:31,122][__main__][INFO] - Starting testing!
[2024-03-12 20:23:37,311][__main__][INFO] - Best ckpt path: D:\data\CIFAR10_logs\logs\train\runs\2024-03-12_20-21-59\checkpoints\epoch_001.ckpt
[2024-03-12 20:23:37,313][src.utils.utils][INFO] - Output dir: D:\data\CIFAR10_logs\logs\train\runs\2024-03-12_20-21-59
[2024-03-12 20:23:37,313][src.utils.utils][INFO] - Closing wandb!
